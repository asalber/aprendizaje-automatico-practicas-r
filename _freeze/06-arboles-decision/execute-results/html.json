{
  "hash": "1b2d1871f17770311ee829a717375bd8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Árboles de decisión y bosques aleatorios\nlang: es\n---\n\n\n\nLos árboles de decisión son modelos de aprendizaje supervisado sencillos que además son fáciles de interpretar. Los árboles crecen desde la raíz, que contiene todos los casos del ejemplo de entrenamiento, hasta las hojas, que contienen los casos clasificados. En cada nodo del árbol se realiza una división del conjunto de casos del nodo en función de una característica del conjunto de datos, de manera que para cada valor de la característica se obtiene un subconjunto de casos que presentan ese valor. El objetivo es dividir los datos de tal manera que las instancias en cada hoja sean lo más homogéneas posible con respecto a la variable respuesta. Aunque su uso más habitual es para problemas de clasificación, también pueden ser utilizados para problemas de regresión.\n\nEn esta práctica también veremos los bosques aleatorios, que son un conjunto de árboles de decisión entrenados con diferentes subconjuntos de datos y características. Los bosques aleatorios son una técnica de ensamblaje que mejora la precisión y la robustez de los modelos de árboles de decisión individuales.\n\n## Ejercicios Resueltos\n\nPara la realización de esta práctica se requieren los siguientes paquetes:\n\n```r\nlibrary(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - ggplot2: para la visualización de datos.\nlibrary(tidymodels)\n# Incluye los siguientes paquetes:\n# - recipes: para la preparación de los datos. \n# - parsnip: para la creación de modelos.\n# - workflows: para la creación de flujos de trabajo.\n# - rsample: para la creación de particiones de los datos.\n# - yardstick: para la evaluación de modelos.\n# - tune: para la optimización de hiperparámetros.\nlibrary(skimr) # para el análisis exploratorio de datos.\nlibrary(rpart.plot) # para la visualización de árboles de decisión.\nlibrary(parallel) # para el entrenamiento en paralelo de modelos.\nlibrary(ranger) # para la creación de modelos de bosque aleatorio.\nlibrary(vip) # para la visualización de la importancia de las variables.\nlibrary(knitr) # para el formateo de tablas.\n```\n\n:::{#exr-arboles-decision-infarto}\nEl fichero [`infartos.csv`](datos/infartos.csv) contiene información sobre distintas variables fisiológicas relacionadas con el riesgo de infarto de una muestra de personas. Las variables que contienen son:\n\n- `Edad`: Edad del paciente (años)\n- `Sexo`: Sexo del paciente (H: hombre, M: mujer)\n- `DolorPecho`: Tipo de dolor torácico (TA: angina típica, ATA: angina atípica, NAP: dolor no anginoso, ASY: asintomático)\n- `PresionArterial`: Presión arterial sistólica en reposo (mm Hg)\n- `Colesterol`: Colesterol sérico (mm/dl)\n-  `Glucemia`: Glucemia en ayunas (1: si glucemia en ayunas > 120 mg/dl, 0: de lo contrario)\n- `Electro`: resultados del electrocardiograma en reposo (Normal: normal, ST: anomalía onda ST-T (inversiones de onda T y/o elevación o depresión de ST > 0,05 mV), LVH: hipertrofia ventricular izquierda probable o definitiva según criterios de Estes)\n- `Pulsaciones`: Frecuencia cardíaca máxima alcanzada (valor numérico entre 60 y 202)\n- `AnginaEjercicio`: Angina inducida por ejercicio (S: sí, N: no)\n- `DepresionST`: Depresión del segmento ST inducida por el ejercicio (valor numérico de la depresión).\n- `PendienteST`: Pendiente del segmento ST en el pico de ejercicio (Ascendente, Plano, Descencdente).\n- `Infarto`: Riesgo de infarto (1: Sí, 0: No)\n\na.  Cargar los datos del archivo [`infartos.csv`](datos/infartos.csv) en un data frame.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(tidyverse)\n    # Cargamos los datos del fichero infartos.csv en un data frame.\n    df <- read.csv(\"https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/infartos.csv\", stringsAsFactors = TRUE)\n    # Mostramos un resumen del data frame.\n    glimpse(df)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    Rows: 918\n    Columns: 12\n    $ Edad            <int> 40, 49, 37, 48, 54, 39, 45, 54, 37, 48, 37, 58, 39, 49…\n    $ Sexo            <fct> H, M, H, M, H, H, M, H, H, M, M, H, H, H, M, M, H, M, …\n    $ DolorPecho      <fct> ATA, NAP, ATA, ASY, NAP, NAP, ATA, ATA, ASY, ATA, NAP,…\n    $ PresionArterial <int> 140, 160, 130, 138, 150, 120, 130, 110, 140, 120, 130,…\n    $ Colesterol      <int> 289, 180, 283, 214, 195, 339, 237, 208, 207, 284, 211,…\n    $ Glucemia        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n    $ Electro         <fct> Normal, Normal, ST, Normal, Normal, Normal, Normal, No…\n    $ Pulsaciones     <int> 172, 156, 98, 108, 122, 170, 170, 142, 130, 120, 142, …\n    $ AnginaEjercicio <fct> N, N, N, S, N, N, N, N, S, N, N, S, N, S, N, N, N, N, …\n    $ DepresionST     <dbl> 0.0, 1.0, 0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 1.5, 0.0, 0.0,…\n    $ PendienteST     <fct> Ascendente, Plano, Ascendente, Plano, Ascendente, Asce…\n    $ Infarto         <int> 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, …\n    ```\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Convertir la variable `Infarto` a un factor con dos niveles: Sí (1) y No (0).\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Recodificamos los valores de Infarto y lo convertimos en un factor.\n    df <- df |> mutate(Infarto = factor(case_match(Infarto,\n        0 ~ \"No\",\n        1 ~ \"Sí\"\n    )))\n    ```\n    :::\n\n    :::\n\na.  Realizar un análisis exploratorio de los datos. ¿Qué variables son numéricas y cuáles categóricas? ¿Hay valores perdidos? ¿Qué tipo de variables son las que contienen información sobre el riesgo de infarto?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(skimr)\n    # Realizamos un análisis exploratorio de los datos.\n    skim(df)\n    ```\n    \n    ::: {.cell-output-display}\n    \n    Table: Data summary\n    \n    |                         |     |\n    |:------------------------|:----|\n    |Name                     |df   |\n    |Number of rows           |918  |\n    |Number of columns        |12   |\n    |_______________________  |     |\n    |Column type frequency:   |     |\n    |factor                   |6    |\n    |numeric                  |6    |\n    |________________________ |     |\n    |Group variables          |None |\n    \n    \n    **Variable type: factor**\n    \n    |skim_variable   | n_missing| complete_rate|ordered | n_unique|top_counts                           |\n    |:---------------|---------:|-------------:|:-------|--------:|:------------------------------------|\n    |Sexo            |         0|             1|FALSE   |        2|H: 725, M: 193                       |\n    |DolorPecho      |         0|             1|FALSE   |        4|ASY: 496, NAP: 203, ATA: 173, TA: 46 |\n    |Electro         |         0|             1|FALSE   |        3|Nor: 552, LVH: 188, ST: 178          |\n    |AnginaEjercicio |         0|             1|FALSE   |        2|N: 547, S: 371                       |\n    |PendienteST     |         0|             1|FALSE   |        3|Pla: 460, Asc: 395, Des: 63          |\n    |Infarto         |         0|             1|FALSE   |        2|Sí: 508, No: 410                     |\n    \n    \n    **Variable type: numeric**\n    \n    |skim_variable   | n_missing| complete_rate|   mean|     sd|   p0|    p25|   p50|   p75|  p100|hist  |\n    |:---------------|---------:|-------------:|------:|------:|----:|------:|-----:|-----:|-----:|:-----|\n    |Edad            |         0|             1|  53.51|   9.43| 28.0|  47.00|  54.0|  60.0|  77.0|▁▅▇▆▁ |\n    |PresionArterial |         0|             1| 132.40|  18.51|  0.0| 120.00| 130.0| 140.0| 200.0|▁▁▃▇▁ |\n    |Colesterol      |         0|             1| 198.80| 109.38|  0.0| 173.25| 223.0| 267.0| 603.0|▃▇▇▁▁ |\n    |Glucemia        |         0|             1|   0.23|   0.42|  0.0|   0.00|   0.0|   0.0|   1.0|▇▁▁▁▂ |\n    |Pulsaciones     |         0|             1| 136.81|  25.46| 60.0| 120.00| 138.0| 156.0| 202.0|▁▃▇▆▂ |\n    |DepresionST     |         0|             1|   0.89|   1.07| -2.6|   0.00|   0.6|   1.5|   6.2|▁▇▆▁▁ |\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Dividir el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test. Utilizar el 80% de los datos para entrenamiento y el 20% restante para test.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`initial_split`](https://rsample.tidymodels.org/reference/initial_split.html) del paquete [`rsample`](https://rsample.tidymodels.org/) para dividir el conjunto de datos en entrenamiento y test.\n\n    Parámetros:\n    - `data`: el data frame con los datos.\n    - `prop`: la proporción del conjunto de datos que se utilizará para el conjunto de entrenamiento (en este caso, 0.8 para el 80%).\n    - `strata`: la variable de estratificación (en este caso, `Especie`) para asegurar que la distribución de clases se mantenga en ambos conjuntos.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(tidymodels)\n    # Establecemos la semilla para la reproducibilidad.\n    set.seed(123)\n    # Dividimos el conjunto de datos en entrenamiento (80%) y test (20%) estratificando por la variable Infarto.\n    df_particion <- initial_split(df, prop = 0.8, strata = Infarto)\n    # Extraemos el conjunto de datos de entrenamiento.\n    df_entrenamiento <- training(df_particion)\n    # Extraemos el conjunto de datos de test.\n    df_test <- testing(df_particion)\n    ```\n    :::\n\n    :::\n\na.  Construir un árbol de decisión para predecir el riesgo de infarto.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`decision_tree`](https://parsnip.tidymodels.org/reference/decision_tree.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/index.html) para crear un modelo de árbol de decisión.\n\n    Parámetros:\n    - `tree_depth`: la profundidad máxima del árbol (5 por defecto).\n    - `cost_complexity`: el coste por complejidad del árbol (0.01 por defecto).\n    - `min_n`: el número mínimo de observaciones en un nodo para que se realice una división (1 por defecto).\n\n    Después, utilizar la función [`set_engine`](https://parsnip.tidymodels.org/reference/set_engine.html) para especificar el motor a utilizar (en este caso, `rpart`).\n\n    Finalmente, utilizar la función [`set_mode`](https://parsnip.tidymodels.org/reference/set_mode.html) para especificar que se trata de un modelo de clasificación.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Creamos un modelo de árbol de decisión.\n    modelo <- decision_tree() |> \n        # Establecemos el motor de rpart.\n        set_engine(\"rpart\") |> \n        # Establecemos el modo de clasificación.\n        set_mode(\"classification\") \n    \n    # Crear un flujo de trabajo con el modelo y los datos de entrenamiento.\n    modelo_entrenado <- workflow() |>\n        # Añadimos la fórmula del modelo.\n        add_formula(Infarto ~ .) |>\n        # Añadimos el modelo de árbol de decisión.\n        add_model(modelo) |>\n        # Ajustamos el modelo a los datos de entrenamiento.\n        fit(data = df_entrenamiento)\n    ```\n    :::\n\n    :::\n\na.  Dibujar el árbol de decisión construido.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`extract_fit_engine`](https://parsnip.tidymodels.org/reference/extract_fit_engine.html) para extraer el modelo entrenado del flujo de trabajo y luego utilizar la función [`rpart.plot`](https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf) para dibujar el árbol de decisión.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(rpart.plot)\n    # Extraemos el modelo ajustado.\n    modelo_entrenado |> extract_fit_engine() |> \n        # Dibujamos el árbol de decisión.\n        rpart.plot()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](06-arboles-decision_files/figure-html/unnamed-chunk-6-1.png){width=672}\n    :::\n    :::\n\n    :::\n\na.  Evaluar el modelo de árbol de decisión con el conjunto de test. Calcular la matriz de confusión y también la precisión, sensibilidad y la especificidad.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la función [`augment`](https://parsnip.tidymodels.org/reference/augment.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/index.html) para añadir al conjunto de test las probabilidades cada especie de pingüino.\n\n    Parámetros:\n    - `new_data`: el conjunto de datos de test.\n\n    Usar la función [`conf_mat`](https://yardstick.tidymodels.org/reference/conf_mat.html) del paquete [`yardstick`](https://yardstick.tidymodels.org/) para calcular la matriz de confusión.\n\n    Parámetros:\n    - `truth`: la variable respuesta (en este caso, `Especie`).\n    - `estimate`: la variable con las clases predichas por el modelo (en este caso, `.pred_class`).\n\n    Usar la función [`metric_set`](https://yardstick.tidymodels.org/reference/metric_set.html) del paquete [`yardstick`](https://yardstick.tidymodels.org/) para crear un conjunto de métricas de evaluación del modelo. En este caso se utilizarán las métricas de precisión (`accuracy`), sensibilidad (`sensitivity`) y especificidad (`specificity`).\n\n    Usar la función [`metrics`](https://yardstick.tidymodels.org/reference/metrics.html) del paquete [`yardstick`](https://yardstick.tidymodels.org/) para calcular las métricas de evaluación del modelo.\n\n    Parámetros:\n    - `truth`: la variable respuesta (en este caso, `Especie`).\n    - `estimate`: la variable con las clases predichas por el modelo (en este case, `.pred_class`).\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Ampliamos el conjunto de test con las predicciones del modelo.\n    df_test_aumentado <- modelo_entrenado |> augment(new_data = df_test) \n    # Calculamos la matriz de confusión.\n    matriz_confusion <- df_test_aumentado |> conf_mat(truth = Infarto, estimate = .pred_class)\n    matriz_confusion$table |> kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |   | No| Sí|\n    |:--|--:|--:|\n    |No | 71| 17|\n    |Sí | 11| 85|\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    # Calculamos la precisión, sensibilidad y especificidad.\n    metricas <- metric_set(accuracy, sensitivity, specificity)\n    df_test_aumentado |> metricas(truth = Infarto, estimate = .pred_class) |> \n        kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric     |.estimator | .estimate|\n    |:-----------|:----------|---------:|\n    |accuracy    |binary     | 0.8478261|\n    |sensitivity |binary     | 0.8658537|\n    |specificity |binary     | 0.8333333|\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Explorar para qué parámetros del árbol se obtiene el mejor modelo. En particular, estudiar la profundidad máxima del árbol, el coste por complejidad y el mínimo número de casos necesario para dividir un nodo. Calcular la precisión del modelo mediante validación cruzada de 5 pliegues.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`tune()`](https://hardhat.tidymodels.org/reference/tune.html) del paquete [`hardhat`](https://hardhat.tidymodels.org/) para definir el parámetro a optimizar en el modelo de árbol de decisión. En este caso, se pueden definir los siguientes parámetros:\n    - `tree_depth`: la profundidad máxima del árbol.\n    - `cost_complexity`: el coste por complejidad del árbol.\n    - `min_n`: el número mínimo de casos necesario para dividir un nodo.\n\n    Después, utilizar la función [`tune_grid`](https://tune.tidymodels.org/reference/tune_grid.html) del paquete [`tune`](https://tune.tidymodels.org/) para optimizar los parámetros del modelo de árbol de decisión.\n\n    Parámetros:\n    - `resamples`: el conjunto de datos de entrenamiento particionado en pliegues para validación cruzada (en este caso, `vfold_cv(df_entrenamiento, v = 5)`).\n    - `grid`: un data frame con los valores de los parámetros a probar.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Definimos el modelo de árbol de decisión con los parámetros a optimizar.\n    modelo <- decision_tree(\n        tree_depth = tune(), # Profundidad máxima del árbol.\n        cost_complexity = tune(), # Coste por complejidad.\n        min_n = tune() # Mínimo número de casos necesario para dividir un nodo.\n    ) |> \n        # Establecemos el motor de entrenamiento de rpart.\n        set_engine(\"rpart\") |> \n        # Establecemos el modo de clasificación.\n        set_mode(\"classification\")\n    \n    # Creamos un flujo de trabajo con el modelo y los datos de entrenamiento.\n    flujo <- workflow() |>\n        # Añadimos la fórmula del modelo.\n        add_formula(Infarto ~ .) |>\n        # Añadimos el modelo de árbol de decisión.\n        add_model(modelo)\n    \n    # Entrenamos el modelo con validación cruzada de 5 pliegues.\n    modelos_entrenados <- flujo |> tune_grid(\n            resamples = vfold_cv(df_entrenamiento, v = 5),\n            grid = expand.grid(\n                tree_depth = 3:6, # Profundidad máxima del árbol.\n                cost_complexity = seq(0, 0.5, by = 0.02), # Coste por complejidad.\n                min_n = 10:15 # Mínimo número de casos necesario para dividir un nodo.\n            ),\n            metrics = metric_set(accuracy) # Métricas a calcular.\n        ) \n    ```\n    :::\n\n    :::\n\na.  Construir el árbol de decisión con los parámetros óptimos obtenidos en el apartado anterior.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`select_best`](https://tune.tidymodels.org/reference/select_best.html) del paquete [`tune`](https://tune.tidymodels.org/) para seleccionar los mejores parámetros de los modelos entrenados.\n    \n    Parámetros:\n    - `modelos_entrenados`: el objeto con los modelos entrenados.\n    - `metric`: la métrica a utilizar para seleccionar los mejores parámetros (en este caso, `accuracy`).\n\n    Después, utilizar la función [`finalize_workflow`](https://workflows.tidymodels.org/reference/finalize_workflow.html) del paquete [`workflows`](https://workflows.tidymodels.org/) para finalizar el flujo de trabajo con los mejores parámetros.\n\n    Parámetros:\n    - Los mejores parámetros de los modelos entrenados.\n    \n    Finalmente, utilizar la función [`last_fit`](https://workflows.tidymodels.org/reference/last_fit.html) del paquete [`workflows`](https://workflows.tidymodels.org/) para entrenar el modelo con el conjunto de entrenamiento y evaluarlo con el conjunto de test.\n\n    Parámetros:\n    - `split`: el objeto con la partición de los datos (en este caso, `df_particion`).\n    - `metrics`: las métricas a utilizar para evaluar el modelo.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Extraemos los mejores parámetros.\n    parametros_optimos <- modelos_entrenados |> select_best(metric = \"accuracy\") \n    parametros_optimos |> kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    | cost_complexity| tree_depth| min_n|.config                |\n    |---------------:|----------:|-----:|:----------------------|\n    |               0|          3|    11|Preprocessor1_Model105 |\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    # Entrenamos el modelo con los mejores parámetros.\n    modelo_final <- flujo |> finalize_workflow(parametros_optimos) |>\n        last_fit(split = df_particion, metrics = metricas) \n    \n    # Extraemos las métricas de evaluación del modelo entrenado.\n    collect_metrics(modelo_final) |> kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric     |.estimator | .estimate|.config              |\n    |:-----------|:----------|---------:|:--------------------|\n    |accuracy    |binary     | 0.8478261|Preprocessor1_Model1 |\n    |sensitivity |binary     | 0.8658537|Preprocessor1_Model1 |\n    |specificity |binary     | 0.8333333|Preprocessor1_Model1 |\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Dibujar el árbol de decisión final.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Extraemos el modelo ajustado.\n    modelo_final |> extract_fit_engine() |> \n        # Dibujamos el árbol de decisión.\n        rpart.plot()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](06-arboles-decision_files/figure-html/unnamed-chunk-10-1.png){width=672}\n    :::\n    :::\n\n    :::\n\na.  Dibujar un diagrama con la importancia de las variables del árbol de decisión.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`vip`](https://koalaverse.github.io/vip/reference/vip.html) del paquete [`vip`](https://koalaverse.github.io/vip/index.html) para dibujar la importancia de las variables del modelo.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(vip)\n    # Extraemos el modelo ajustado.\n    modelo_final |> extract_fit_engine() |> \n        # Dibujamos la importancia de las variables.\n        vip()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](06-arboles-decision_files/figure-html/unnamed-chunk-11-1.png){width=672}\n    :::\n    :::\n\n    :::\n\na.  Construir bosques aleatorios para predecir el riesgo de infarto, explorando para qué parámetros se obtiene el mejor modelo. En particular, estudiar el número de variables a considerar en cada división y el mínimo número de casos necesario para dividir un nodo. Calcular la precisión y en área bajo la curva ROC del modelo mediante validación cruzada de 5 pliegues.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`rand_forest`](https://parsnip.tidymodels.org/reference/rand_forest.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/) para crear un modelo de bosque aleatorio.\n\n    Parámetros:\n    - `trees`: el número de árboles en el bosque (1000 por defecto).\n    - `mtry`: el número de variables a considerar en cada división (se puede utilizar `tune()` para optimizar este parámetro).\n    - `min_n`: el número mínimo de casos necesario para dividir un nodo (se puede utilizar `tune()` para optimizar este parámetro).\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Número de procesadores para el entrenamiento en paralelo.\n    library(parallel)\n    procesadores <- detectCores() - 1 # Usamos todos menos uno para evitar saturar el sistema.\n    # Creamos un modelo de bosque aleatorio.\n    modelo_bosque <- rand_forest(\n        trees = 1000, # Número de árboles en el bosque.\n        mtry = tune(), # Número de variables a considerar en cada división.\n        min_n = tune() # Mínimo número de casos necesario para dividir un nodo.\n    ) |> \n        # Establecemos el motor de ranger.\n        set_engine(\"ranger\", num.threads = procesadores, importance = \"impurity\") |> \n        # Establecemos el modo de clasificación.\n        set_mode(\"classification\")\n    \n    # Creamos un flujo de trabajo con el modelo y los datos de entrenamiento.\n    flujo_bosque <- workflow() |>\n        # Añadimos la fórmula del modelo.\n        add_formula(Infarto ~ .) |>\n        # Añadimos el modelo de bosque aleatorio.\n        add_model(modelo_bosque)\n    \n    # Dividimos el conjunto de entrenamiento en entrenamiento y validación estratificando por la variable Infarto.\n    df_validacion <- validation_split(df_entrenamiento, prop = 0.8, strata = Infarto) \n    \n    # Establecemos una semilla aleatoria para la reproducibilidad.\n    set.seed(123)\n    # Entrenamos el modelo con validación cruzada de 5 pliegues.\n    # Utilizamos la función tune_grid para optimizar los parámetros mtry y min_n.\n    modelos_entrenados <- flujo_bosque |> tune_grid(\n        # Utilizamos validación cruzada de 5 pliegues.\n        resamples = vfold_cv(df_entrenamiento, v = 5), \n        # Indicamos que pruebe con 25 valores distintos de mtry y min_n.\n        grid = 25,\n        # Guardamos las predicciones para cada pliegue.\n        control = control_grid(save_pred = TRUE), \n        # Definimos como métricas la precisión y el área bajo la curva ROC.\n        metrics = metric_set(accuracy, roc_auc)\n    )\n    \n    # Visualizamos los resultados de la validación cruzada.\n    autoplot(modelos_entrenados) \n    ```\n    \n    ::: {.cell-output-display}\n    ![](06-arboles-decision_files/figure-html/unnamed-chunk-12-1.png){width=672}\n    :::\n    \n    ```{.r .cell-code}\n    # Extraemos los parámetros del mejor modelo entrenado según el área bajo la curva ROC.\n    parametros_optimos <- modelos_entrenados |> select_best(metric = \"roc_auc\")\n    ```\n    :::\n\n    :::\n\na.  Construir el bosque aleatorio con los parámetros óptimos obtenidos en el apartado anterior y evaluarlo con el conjunto de test. Calcular la precisión, el área bajo la curva ROC y dibujar la curva ROC del modelo.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    modelo_final <- flujo_bosque |> \n        # Seleccionamos el mejor modelo entrenado según el área bajo la curva ROC.\n        finalize_workflow(select_best(modelos_entrenados, metric = \"roc_auc\")) |> \n        # Entrenamos el modelo con el conjunto de entrenamiento y lo evaluamos con el conjunto de test usando las métricas de precisión y área bajo la curva ROC.\n        last_fit(df_particion, metrics = metric_set(accuracy, roc_auc))\n    \n    # Extraemos las métricas de evaluación del modelo entrenado.\n    collect_metrics(modelo_final) |> kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric  |.estimator | .estimate|.config              |\n    |:--------|:----------|---------:|:--------------------|\n    |accuracy |binary     | 0.8967391|Preprocessor1_Model1 |\n    |roc_auc  |binary     | 0.9506217|Preprocessor1_Model1 |\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    # Extraemos las predicciones del modelo.\n    modelo_final |> collect_predictions() |> \n        # Dibujamos la curva ROC.\n        roc_curve(Infarto, .pred_No) |> \n        autoplot() + \n        labs(title = \"Curva ROC del modelo de bosque aleatorio\")\n    ```\n    \n    ::: {.cell-output-display}\n    ![](06-arboles-decision_files/figure-html/unnamed-chunk-13-1.png){width=672}\n    :::\n    :::\n\n    :::\n\na.  Dibujar un diagrama con la importancia de las variables del bosque aleatorio.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Extraemos el modelo ajustado del flujo de trabajo.\n    modelo_final |> extract_fit_engine() |> \n        # Dibujamos la importancia de las variables.\n        vip()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](06-arboles-decision_files/figure-html/unnamed-chunk-14-1.png){width=672}\n    :::\n    :::\n\n    :::\n:::\n\n\n## Ejercicios Propuestos\n\n:::{#exr-no-supervisado-vinos}\nEl fichero [`vinos.csv`](datos/vinos.csv) contiene información sobre las características de vinos blancos y tintos portugueses de la denominación \"Vinho Verde\". Las variables que contiene son las siguientes:\n\n| Variable             | Descripción                                                           | Tipo (unidades)        |\n|----------------------------------------|-----------------------------------------------------------------------|------------------------|\n| tipo                 | Tipo de vino                                                          | Factor (blanco, tinto) |\n| meses.barrica        | Meses de envejecimiento en barrica                               | Numérica(meses)  |\n| acided.fija          | Cantidad de ácidotartárico                                 | Numérica(g/dm3)  |\n| acided.volatil       | Cantidad de ácido acético                                             | Numérica(g/dm3)  |\n| acido.citrico        | Cantidad de ácidocítrico                                        | Numérica(g/dm3)  |\n| azucar.residual      | Cantidad de azúcar remanente después de la fermentación          | Numérica(g/dm3)  |\n| cloruro.sodico       | Cantidad de clorurosódico                                       | Numérica(g/dm3)  |\n| dioxido.azufre.libre | Cantidad de dióxido de azufre en forma libre                | Numérica(mg/dm3) |\n| dioxido.azufre.total | Cantidad de dióxido de azufre total en forma libre o ligada | Numérica(mg/dm3) |\n| densidad             | Densidad                                                              | Numérica(g/cm3)  |\n| ph                   | pH                                                                    | Numérica(0-14)   |\n| sulfatos             | Cantidad de sulfato de potasio                                   | Numérica(g/dm3)  |\n| alcohol              | Porcentaje de contenido de alcohol                          | Numérica(0-100)  |\n| calidad              | Calificación otorgada por un panel de expertos                   | Numérica(0-10)   |\n\na.  Crear un dataframe con los datos del archivo [`vinos.csv`](datos/vinos.csv).\n\na.  Realizar un análisis exploratorio de los datos.\n\na.  Dividir el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test. Utilizar el 80% de los datos para entrenamiento y el 20% restante para test.\n\na.  Construir un árbol de decisión para predecir la calidad del vino. Explorar para qué parámetros del árbol se obtiene el mejor modelo evaluando los modelos con validación cruzada de 5 pliegues.\n\na.  Evaluar el mejor modelo de árbol de decisión con el conjunto de test. Calcular la matriz de confusión y también la precisión, sensibilidad y la especificidad.\n\na.  Dibujar el árbol de decisión construido.\n\na.  Dibujar un diagrama con la importancia de las variables del árbol de decisión.\n\na.  Construir bosques aleatorios para predecir la calidad del vino, explorando para qué parámetros se obtiene el mejor modelo evaluando los modelos con validación cruzada de 5 pliegues.\n\na.  Construir el bosque aleatorio con los parámetros óptimos obtenidos en el apartado anterior y evaluarlo con el conjunto de test. Calcular la precisión, el área bajo la curva ROC y dibujar la curva ROC del modelo.\n\na.  Dibujar un diagrama con la importancia de las variables del bosque aleatorio.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}