{
  "hash": "3b26723efa9897b48d5d26d8b01cbc7a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Redes Neuronales\nlang: es\n---\n\n\n\nLas redes de neuronas artificiales son un modelo computacional inspirado en el funcionamiento del cerebro humano. Una neurona artificial es una unidad de cómputo bastante simple, que recibe una serie de entradas, las procesa y produce una salida. La salida de una neurona puede ser la entrada de otra neurona, formando así una red de neuronas interconectadas, donde cada conexión tiene un peso asociado. Es esta red, que a veces contiene miles y millones de neuronas, la que dota de gran potencia de cálculo a este modelo, siendo capaces de aprender patrones de datos muy complejos, como imágenes, texto o sonido, y por tanto, se utilizan a menudo en tareas de clasificación o regresión.\n\nEl aprendizaje en una red neuronal consiste en ajustar los pesos de las conexiones para minimizar el error entre la salida predicha y la salida real.\n\n## Ejercicios Resueltos\n\nPara la realización de esta práctica se requieren los siguientes paquetes:\n\n```r\nlibrary(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - ggplot2: para la visualización de datos.\nlibrary(tidymodels)\n# Incluye los siguientes paquetes:\n# - recipes: para la preparación de los datos. \n# - parsnip: para la creación de modelos.\n# - workflows: para la creación de flujos de trabajo.\n# - rsample: para la creación de particiones de los datos.\n# - yardstick: para la evaluación de modelos.\n# - tune: para la optimización de hiperparámetros.\nlibrary(skimr) # para el análisis exploratorio de datos.\nlibrary(brulee) # Para entrenar redes neuronales con `torch`.\nlibrary(knitr) # para el formateo de tablas.\n```\n\n:::{#exr-arboles-decision-cancer}\nEl conjunto de datos [cancer-mama.csv](datos/cancer-mama.csv) contiene información sobre las características de núcleos de células mamarias obtenidas de imágenes digitalizadas tanto de células cancerosas como no cancerosas obtenidas por biopsia. Las variables que contiene son:\n\n- ID: Identificador único de la muestra.\n- Diagnostico: Diagnóstico de la muestra (M: maligno, B: benigno).\n- Radio: Media de la distancia desde el centro hasta los puntos de la superficie.\n- Textura: Desviación estándar de la intensidad de gris de los puntos.\n- Perímetro: Longitud del contorno.\n- Área: Área de la imagen.\n- Suavidad: Variación local en la longitud del radio.\n- Compacidad: Perímetro^2 / Área - 1.0.\n- Concavidad: Magnitud de las porciones cóncavas del contorno.\n- Puntos_concavos: Número de puntos cóncavos del contorno.\n- Simetría: Simetría de la imagen.\n- Irregularidad: Medida de la irregularidad de la forma.\n\na.  Crear un dataframe con los datos del archivo [`cancer-mama.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/cancer-mama.csv).\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(tidyverse)\n    df <- read.csv(\"https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/cancer-mama.csv\", stringsAsFactors = TRUE) |>\n        # Convertimos la variable Diagnostico a un factor.\n        mutate(Diagnostico = factor(Diagnostico, levels = c(\"B\", \"M\"), labels = c(\"Benigno\", \"Maligno\")))\n    glimpse(df)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    Rows: 569\n    Columns: 12\n    $ ID              <int> 842302, 842517, 84300903, 84348301, 84358402, 843786, …\n    $ Diagnostico     <fct> Maligno, Maligno, Maligno, Maligno, Maligno, Maligno, …\n    $ Radio           <dbl> 17.990, 20.570, 19.690, 11.420, 20.290, 12.450, 18.250…\n    $ Textura         <dbl> 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.98, 20.83…\n    $ Perimetro       <dbl> 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, 119.60, …\n    $ Area            <dbl> 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, 1040.0, …\n    $ Suavidad        <dbl> 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0.12780, …\n    $ Compacidad      <dbl> 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0.17000, …\n    $ Concavidad      <dbl> 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0.15780, …\n    $ Puntos_Concavos <dbl> 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0.08089, …\n    $ Simetria        <dbl> 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087, 0.1794…\n    $ Irregularidad   <dbl> 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0.07613, …\n    ```\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Hacer un análisis exploratorio de los datos.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(skimr)\n    skim(df)\n    ```\n    \n    ::: {.cell-output-display}\n    \n    Table: Data summary\n    \n    |                         |     |\n    |:------------------------|:----|\n    |Name                     |df   |\n    |Number of rows           |569  |\n    |Number of columns        |12   |\n    |_______________________  |     |\n    |Column type frequency:   |     |\n    |factor                   |1    |\n    |numeric                  |11   |\n    |________________________ |     |\n    |Group variables          |None |\n    \n    \n    **Variable type: factor**\n    \n    |skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts         |\n    |:-------------|---------:|-------------:|:-------|--------:|:------------------|\n    |Diagnostico   |         0|             1|FALSE   |        2|Ben: 357, Mal: 212 |\n    \n    \n    **Variable type: numeric**\n    \n    |skim_variable   | n_missing| complete_rate|        mean|           sd|      p0|       p25|       p50|        p75|         p100|hist  |\n    |:---------------|---------:|-------------:|-----------:|------------:|-------:|---------:|---------:|----------:|------------:|:-----|\n    |ID              |         0|             1| 30371831.43| 125020585.61| 8670.00| 869218.00| 906024.00| 8813129.00| 911320502.00|▇▁▁▁▁ |\n    |Radio           |         0|             1|       14.13|         3.52|    6.98|     11.70|     13.37|      15.78|        28.11|▂▇▃▁▁ |\n    |Textura         |         0|             1|       19.29|         4.30|    9.71|     16.17|     18.84|      21.80|        39.28|▃▇▃▁▁ |\n    |Perimetro       |         0|             1|       91.97|        24.30|   43.79|     75.17|     86.24|     104.10|       188.50|▃▇▃▁▁ |\n    |Area            |         0|             1|      654.89|       351.91|  143.50|    420.30|    551.10|     782.70|      2501.00|▇▃▂▁▁ |\n    |Suavidad        |         0|             1|        0.10|         0.01|    0.05|      0.09|      0.10|       0.11|         0.16|▁▇▇▁▁ |\n    |Compacidad      |         0|             1|        0.10|         0.05|    0.02|      0.06|      0.09|       0.13|         0.35|▇▇▂▁▁ |\n    |Concavidad      |         0|             1|        0.09|         0.08|    0.00|      0.03|      0.06|       0.13|         0.43|▇▃▂▁▁ |\n    |Puntos_Concavos |         0|             1|        0.05|         0.04|    0.00|      0.02|      0.03|       0.07|         0.20|▇▃▂▁▁ |\n    |Simetria        |         0|             1|        0.18|         0.03|    0.11|      0.16|      0.18|       0.20|         0.30|▁▇▅▁▁ |\n    |Irregularidad   |         0|             1|        0.06|         0.01|    0.05|      0.06|      0.06|       0.07|         0.10|▆▇▂▁▁ |\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Dibujar un diagrama de relación entre todos los pares de variables del conjunto de datos diferenciando por el diagnóstico.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Se puede utilizar la función `ggpairs` del paquete `GGally` para dibujar un diagrama de relación entre todos los pares de variables del conjunto de datos. Asociar el sexo a la dimensión del color.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(GGally)\n    ggpairs(df, aes(color = Diagnostico, alpha = 0.5))\n    ```\n    \n    ::: {.cell-output-display}\n    ![](07-redes-neuronales_files/figure-html/unnamed-chunk-3-1.png){width=672}\n    :::\n    :::\n\n    :::\n\na.  Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba, con una proporción del 80% para el entrenamiento y el 20% para la prueba, estratificando por el diagnóstico.\n\n    ::: {.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`initial_split`](https://rsample.tidymodels.org/reference/initial_split.html) del paquete [`rsample`](https://rsample.tidymodels.org/) para dividir el conjunto de datos en entrenamiento y test.\n\n    Parámetros:\n    - `data`: el data frame con los datos.\n    - `prop`: la proporción del conjunto de datos que se utilizará para el conjunto de entrenamiento (en este caso, 0.8 para el 80%).\n    - `strata`: la variable de estratificación (en este caso, `Diagnostico`) para asegurar que la distribución de clases se mantenga en ambos conjuntos.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(tidymodels)\n    # Establecemos la semilla para la reproducibilidad.\n    set.seed(123)\n    # Dividimos el conjunto de datos en un conjunto de entrenamiento y un conjunto de test.\n    df_particion <- initial_split(df, prop = 0.8, strata = \"Diagnostico\")\n    # Extraemos el conjunto de entrenamiento.\n    df_entrenamiento <- training(df_particion)\n    # Extraemos el conjunto de test.\n    df_test <- testing(df_particion)\n    ```\n    :::\n\n    :::\n\na.  Preprocesar el conjunto de entrenamiento para normalizar las variables numéricas.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Creamos una receta de preprocesamiento.\n    receta <- recipe(Diagnostico ~ ., data = df_entrenamiento) |>\n        # Normalizamos las variables numéricas.\n        step_normalize(all_numeric_predictors())\n    ```\n    :::\n\n    :::\n\na.  Construir una red neuronal con una capa oculta de 10 neuronas para predecir el diagnóstico. Realizar solo dos iteraciones (épocas) de entrenamiento.\n\n    ::: {.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`mlp`](https://parsnip.tidymodels.org/reference/mlp.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/index.html) para crear un modelo de red neuronal.\n\n    Parámetros:\n    - `hidden_units`: el número de neuronas en la capa oculta (10 en este caso).\n    - `activation`: la función de activación a utilizar (por defecto \"relu\").\n    - `dropout`: la proporción de parámetros reseteados a 0 durante el entrenamiento (0.1 por defecto).\n    - `epochs`: el número de épocas de entrenamiento (100 por defecto).\n\n    Después, utilizar la función [`set_engine`](https://parsnip.tidymodels.org/reference/set_engine.html) para especificar el motor a utilizar (en este caso, `brulee`).\n\n    Utilizar la función [`set_mode`](https://parsnip.tidymodels.org/reference/set_mode.html) para especificar que se trata de un modelo de clasificación.\n\n    Finalmente, utilizar la función [`extract_fit_engine`](https://parsnip.tidymodels.org/reference/extract_fit_engine.html) para extraer el modelo entrenado del flujo de trabajo.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    set.seed(123)\n    library(brulee)\n    library(knitr)\n    # Creamos un modelo de red neuronal.\n    modelo <- mlp(hidden_units = 10, epochs = 2) |>\n        set_engine(\"brulee\") |>\n        set_mode(\"classification\")\n    \n    modelo_entrenado <- workflow() |>\n        # Añadimos la receta de preprocesamiento.\n        add_recipe(receta) |>\n        # Añadimos el modelo.\n        add_model(modelo) |>\n        # Entrenamos el modelo.\n        fit(data = df_entrenamiento)\n    \n    modelo_entrenado |>\n        # Mostramos un resumen del modelo.\n        extract_fit_engine()\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    Multilayer perceptron\n    \n    relu activation,\n    10 hidden units,\n    142 model parameters\n    454 samples, 11 features, 2 classes \n    class weights Benigno=1, Maligno=1 \n    weight decay: 0.001 \n    dropout proportion: 0 \n    batch size: 409 \n    learn rate: 0.01 \n    validation loss after 2 epochs: 0.152 \n    ```\n    \n    \n    :::\n    :::\n\n:::\n\na.  Evaluar el modelo con el conjunto de test y calcular la matriz de confusión, la exactitud, y el area bajo la curva ROC.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la función [`augment`](https://parsnip.tidymodels.org/reference/augment.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/index.html) para añadir al conjunto de test las probabilidades cada especie de pingüino.\n\n    Parámetros:\n    - `new_data`: el conjunto de datos de test.\n\n    Usar la función [`conf_mat`](https://yardstick.tidymodels.org/reference/conf_mat.html) del paquete [`yardstick`](https://yardstick.tidymodels.org/) para calcular la matriz de confusión.\n\n    Parámetros:\n    - `truth`: la variable respuesta (en este caso, `Especie`).\n    - `estimate`: la variable con las clases predichas por el modelo (en este caso, `.pred_class`).\n\n    Usar la función [`metrics`](https://yardstick.tidymodels.org/reference/metrics.html) del paquete [`yardstick`](https://yardstick.tidymodels.org/) para calcular las métricas de evaluación del modelo.\n\n    Parámetros:\n    - `truth`: la variable respuesta (en este caso, `Especie`).\n    - `estimate`: la variable con las clases predichas por el modelo (en este case, `.pred_class`).\n\n    Usar la función [`roc_auc`](https://yardstick.tidymodels.org/reference/roc_auc.html) del paquete [`yardstick`](https://yardstick.tidymodels.org/) para calcular el área bajo la curva ROC.\n\n    Parámetros:\n    - `truth`: la variable respuesta (en este caso, `Especie`).\n    - `estimate`: la variable con las probabilidades de la clase positiva (en este caso, `.pred_Benigno`).\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Añadimos las predicciones al conjunto de test.\n    df_test_2 <- modelo_entrenado |> augment(new_data = df_test)\n    \n    # Calculamos la matriz de confusión.\n    matriz_confusion <- df_test_2 |> conf_mat(truth = Diagnostico, estimate = .pred_class) \n    matriz_confusion$table |> kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |        | Benigno| Maligno|\n    |:-------|-------:|-------:|\n    |Benigno |      68|       3|\n    |Maligno |       4|      40|\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    # Calculamos la exactitud.\n    df_test_2 |> metrics(truth = Diagnostico, estimate = .pred_class) |>\n        # Mostramos las métricas de evaluación del modelo.\n        kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric  |.estimator | .estimate|\n    |:--------|:----------|---------:|\n    |accuracy |binary     | 0.9391304|\n    |kap      |binary     | 0.8705996|\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    # Calculamos el área bajo la curva ROC.\n    df_test_2 |> roc_auc(truth = Diagnostico, .pred_Benigno) |>\n        # Mostramos el área bajo la curva ROC.\n        kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric |.estimator | .estimate|\n    |:-------|:----------|---------:|\n    |roc_auc |binary     |  0.993863|\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Volver a entrenar la red neuronal anterior con 10 iteraciones (épocas) y evaluar la exactitud del modelo con el conjunto de test.\n\n    ::: {.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`mlp`](https://parsnip.tidymodels.org/reference/mlp.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/index.html) para crear un modelo de red neuronal.\n\n    Parámetros:\n    - `hidden_units`: el número de neuronas en la capa oculta (10 en este caso).\n    - `activation`: la función de activación a utilizar (por defecto \"relu\").\n    - `dropout`: la proporción de parámetros reseteados a 0 durante el entrenamiento (0.1 por defecto).\n    - `epochs`: el número de épocas de entrenamiento (100 por defecto).\n\n    Después, utilizar la función [`set_engine`](https://parsnip.tidymodels.org/reference/set_engine.html) para especificar el motor a utilizar (en este caso, `brulee`).\n\n    Utilizar la función [`set_mode`](https://parsnip.tidymodels.org/reference/set_mode.html) para especificar que se trata de un modelo de clasificación.\n\n    Finalmente, utilizar la función [`extract_fit_engine`](https://parsnip.tidymodels.org/reference/extract_fit_engine.html) para extraer el modelo entrenado del flujo de trabajo.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    set.seed(123)\n    library(brulee)\n    library(knitr)\n    # Creamos un modelo de red neuronal.\n    modelo <- mlp(hidden_units = 10, epochs = 10) |>\n        set_engine(\"brulee\") |>\n        set_mode(\"classification\")\n    \n    modelo_entrenado <- workflow() |>\n        # Añadimos la receta de preprocesamiento.\n        add_recipe(receta) |>\n        # Añadimos el modelo.\n        add_model(modelo) |>\n        # Entrenamos el modelo.\n        fit(data = df_entrenamiento)\n    \n    # Añadimos las predicciones al conjunto de test.\n    df_test_10 <- modelo_entrenado |> augment(new_data = df_test)\n    \n    # Calculamos la exactitud.\n    df_test_10 |> metrics(truth = Diagnostico, estimate = .pred_class) |>\n        # Mostramos las métricas de evaluación del modelo.\n        kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric  |.estimator | .estimate|\n    |:--------|:----------|---------:|\n    |accuracy |binary     | 0.9652174|\n    |kap      |binary     | 0.9264000|\n    \n    \n    :::\n    :::\n\n    :::\n:::\n\n:::{#exr-redes-neuronales-vinos}\nEl fichero [`vinos.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/vinos.csv) contiene información sobre las características de vinos blancos y tintos portugueses de la denominación \"Vinho Verde\". Las variables que contiene son las siguientes:\n\n\n| Variable             | Descripción                                                           | Tipo (unidades)        |\n|----------------------------------------|-----------------------------------------------------------------------|------------------------|\n| tipo                 | Tipo de vino                                                          | Factor (blanco, tinto) |\n| meses.barrica        | Meses de envejecimiento en barrica                               | Numérica(meses)  |\n| acided.fija          | Cantidad de ácidotartárico                                 | Numérica(g/dm3)  |\n| acided.volatil       | Cantidad de ácido acético                                             | Numérica(g/dm3)  |\n| acido.citrico        | Cantidad de ácidocítrico                                        | Numérica(g/dm3)  |\n| azucar.residual      | Cantidad de azúcar remanente después de la fermentación          | Numérica(g/dm3)  |\n| cloruro.sodico       | Cantidad de clorurosódico                                       | Numérica(g/dm3)  |\n| dioxido.azufre.libre | Cantidad de dióxido de azufre en forma libre                | Numérica(mg/dm3) |\n| dioxido.azufre.total | Cantidad de dióxido de azufre total en forma libre o ligada | Numérica(mg/dm3) |\n| densidad             | Densidad                                                              | Numérica(g/cm3)  |\n| ph                   | pH                                                                    | Numérica(0-14)   |\n| sulfatos             | Cantidad de sulfato de potasio                                   | Numérica(g/dm3)  |\n| alcohol              | Porcentaje de contenido de alcohol                          | Numérica(0-100)  |\n| calidad              | Calificación otorgada por un panel de expertos                   | Numérica(0-10)   |\na.  Crear un data frame con los datos del archivo [`vinos.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/vinos.csv).\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(tidyverse)\n    df <- read.csv(\"datos/vinos.csv\", stringsAsFactors = TRUE)\n    glimpse(df)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    Rows: 5,320\n    Columns: 14\n    $ tipo                 <fct> blanco, blanco, blanco, blanco, blanco, blanco, b…\n    $ meses_barrica        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n    $ acided_fija          <dbl> 7.0, 6.3, 8.1, 7.2, 6.2, 8.1, 8.1, 8.6, 7.9, 6.6,…\n    $ acided_volatil       <dbl> 0.27, 0.30, 0.28, 0.23, 0.32, 0.22, 0.27, 0.23, 0…\n    $ acido_citrico        <dbl> 0.36, 0.34, 0.40, 0.32, 0.16, 0.43, 0.41, 0.40, 0…\n    $ azucar_residual      <dbl> 20.70, 1.60, 6.90, 8.50, 7.00, 1.50, 1.45, 4.20, …\n    $ cloruro_sodico       <dbl> 0.045, 0.049, 0.050, 0.058, 0.045, 0.044, 0.033, …\n    $ dioxido_azufre_libre <dbl> 45, 14, 30, 47, 30, 28, 11, 17, 16, 48, 41, 28, 3…\n    $ dioxido_azufre_total <dbl> 170, 132, 97, 186, 136, 129, 63, 109, 75, 143, 17…\n    $ densidad             <dbl> 1.0010, 0.9940, 0.9951, 0.9956, 0.9949, 0.9938, 0…\n    $ ph                   <dbl> 3.00, 3.30, 3.26, 3.19, 3.18, 3.22, 2.99, 3.14, 3…\n    $ sulfatos             <dbl> 0.45, 0.49, 0.44, 0.40, 0.47, 0.45, 0.56, 0.53, 0…\n    $ alcohol              <dbl> 8.8, 9.5, 10.1, 9.9, 9.6, 11.0, 12.0, 9.7, 10.8, …\n    $ calidad              <int> 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 7, 6, 8, 6, 5, 7…\n    ```\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Realizar un análisis exploratorio de los datos.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(skimr)\n    skim(df)\n    ```\n    \n    ::: {.cell-output-display}\n    \n    Table: Data summary\n    \n    |                         |     |\n    |:------------------------|:----|\n    |Name                     |df   |\n    |Number of rows           |5320 |\n    |Number of columns        |14   |\n    |_______________________  |     |\n    |Column type frequency:   |     |\n    |factor                   |1    |\n    |numeric                  |13   |\n    |________________________ |     |\n    |Group variables          |None |\n    \n    \n    **Variable type: factor**\n    \n    |skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts           |\n    |:-------------|---------:|-------------:|:-------|--------:|:--------------------|\n    |tipo          |         0|             1|FALSE   |        2|bla: 3961, tin: 1359 |\n    \n    \n    **Variable type: numeric**\n    \n    |skim_variable        | n_missing| complete_rate|   mean|    sd|   p0|   p25|    p50|    p75|   p100|hist  |\n    |:--------------------|---------:|-------------:|------:|-----:|----:|-----:|------:|------:|------:|:-----|\n    |meses_barrica        |         0|             1|   1.23|  3.14| 0.00|  0.00|   0.00|   0.00|  24.00|▇▁▁▁▁ |\n    |acided_fija          |         0|             1|   7.22|  1.32| 3.80|  6.40|   7.00|   7.70|  15.90|▂▇▁▁▁ |\n    |acided_volatil       |         0|             1|   0.34|  0.17| 0.08|  0.23|   0.30|   0.41|   1.58|▇▂▁▁▁ |\n    |acido_citrico        |         0|             1|   0.32|  0.15| 0.00|  0.24|   0.31|   0.40|   1.66|▇▅▁▁▁ |\n    |azucar_residual      |         0|             1|   5.03|  4.41| 0.60|  1.80|   2.70|   7.50|  26.05|▇▂▁▁▁ |\n    |cloruro_sodico       |         0|             1|   0.06|  0.04| 0.01|  0.04|   0.05|   0.07|   0.61|▇▁▁▁▁ |\n    |dioxido_azufre_libre |         0|             1|  30.04| 17.81| 1.00| 16.00|  28.00|  41.00| 289.00|▇▁▁▁▁ |\n    |dioxido_azufre_total |         0|             1| 114.11| 56.77| 6.00| 74.00| 116.00| 153.25| 440.00|▅▇▂▁▁ |\n    |densidad             |         0|             1|   0.99|  0.00| 0.99|  0.99|   0.99|   1.00|   1.04|▇▂▁▁▁ |\n    |ph                   |         0|             1|   3.22|  0.16| 2.72|  3.11|   3.21|   3.33|   4.01|▁▇▆▁▁ |\n    |sulfatos             |         0|             1|   0.53|  0.15| 0.22|  0.43|   0.51|   0.60|   2.00|▇▃▁▁▁ |\n    |alcohol              |         0|             1|  10.55|  1.19| 8.00|  9.50|  10.40|  11.40|  14.90|▃▇▅▂▁ |\n    |calidad              |         0|             1|   5.80|  0.88| 3.00|  5.00|   6.00|   6.00|   9.00|▁▆▇▃▁ |\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Recodificar la variable `calidad` en una variable categórica con las siguientes categorías:\n  \n    - Muy malo: 1-2\n    - Malo: 3-4\n    - Regular: 5\n    - Bueno: 6\n    - Muy bueno: 7-8\n    - Excelente: 9-10\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    df <- df |>\n        # Convertimos la variable calidad a un factor.\n        mutate(calidad = factor(case_when(\n            calidad %in% c(1, 2) ~ \"Muy malo\",\n            calidad %in% c(3, 4) ~ \"Malo\",\n            calidad == 5 ~ \"Regular\",\n            calidad == 6 ~ \"Bueno\",\n            calidad %in% c(7, 8) ~ \"Muy bueno\",\n            TRUE ~ \"Excelente\"\n        ), levels = c(\"Muy malo\", \"Malo\", \"Regular\", \"Bueno\", \"Muy bueno\", \"Excelente\")))\n    ```\n    :::\n\n    :::\n\na.  Mostrar la tabla de frecuencias de la variable `calidad`.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    df |>\n        # Mostramos la tabla de frecuencias de la variable calidad.\n        count(calidad) |>\n        # Mostramos la tabla de frecuencias.\n        kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |calidad   |    n|\n    |:---------|----:|\n    |Malo      |  236|\n    |Regular   | 1752|\n    |Bueno     | 2323|\n    |Muy bueno | 1004|\n    |Excelente |    5|\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Dividir el conjunto de datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%) estratificando por la variable `calidad`.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(tidymodels)\n    set.seed(123) # Semilla aleatoria para la reproducibilidad.\n    df_particion <- initial_split(df, prop = 0.8, strata = \"calidad\")  # Dividir el conjunto de datos en entrenamiento (80%) y test (20%).\n    df_entrenamiento <- training(df_particion) # Extraemos el conjunto de entrenamiento.\n    df_test <- testing(df_particion) # Extraemos el conjunto de test.\n    ```\n    :::\n\n    :::\n\na.  Establecer la `calidad` como variable objetivo, normalizar las variables predictivas y convertir las variables categóricas en variables numéricas dummy.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Definimos la receta de preprocesamiento.\n    receta <- recipe(calidad ~ ., data = df_entrenamiento) |> \n        # Normalizamos las variables numéricas.\n        step_normalize(all_numeric_predictors()) |> \n        # Convertimos las variables categóricas en variables dummy.\n        step_dummy(all_nominal_predictors()) \n    ```\n    :::\n\n    :::\n\na.  Construir una red neuronal para predecir la calidad del vino explorando distintos valores para el número de neuronas en la capa oculta (10, 15, 20, 25) mediante validación cruzada con 5 pliegues. Utilizar la precisión y el área bajo la curva ROC como métricas de evaluación.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la función [`tune()`](https://hardhat.tidymodels.org/reference/tune.html) del paquete [`hardhat`](https://hardhat.tidymodels.org/) para definir los parámetros a optimizar. En este caso, se pueden definir los siguientes parámetros:\n    - `hidden_units`: el número de neuronas en la capa oculta.\n\n    Después, utilizar la función [`tune_grid`](https://tune.tidymodels.org/reference/tune_grid.html) del paquete [`tune`](https://tune.tidymodels.org/) para optimizar los parámetros del modelo de la red neuronal.\n\n    Parámetros:\n    - `resamples`: el conjunto de datos de entrenamiento particionado en pliegues para validación cruzada (en este caso, `vfold_cv(df_entrenamiento, v = 5)`).\n    - `grid`: un data frame con los valores de los parámetros a probar.\n\n    Usar la función [`autoplot()`](https://tune.tidymodels.org/reference/autoplot.tune_results.html) del paquete [`tune`](https://tune.tidymodels.org/) para visualizar los resultados de la optimización.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    set.seed(123) # Semilla aleatoria para la reproducibilidad.\n    library(brulee)\n    # Creamos un modelo de red neuronal con un número variable de neuronas en la capa oculta.\n    modelo <- mlp(hidden_units = tune()) |>\n        set_engine(\"brulee\") |>\n        set_mode(\"classification\")\n    \n    flujo <- workflow() |>\n        # Añadimos la receta de preprocesamiento.\n        add_recipe(receta) |>\n        # Añadimos el modelo.\n        add_model(modelo)\n    \n    modelos_entrenados <- flujo |>\n    # Entrenamos los modelos con diferentes valores de neuronas en la capa oculta.\n        tune_grid(\n            resamples = vfold_cv(df_entrenamiento, v = 5), # Validación cruzada con 5 pliegues.\n            control = control_grid(save_pred = TRUE), # Guardamos las predicciones.\n            grid = tibble(hidden_units = seq(10, 25, by = 5)), # Valores de neuronas a probar.\n            metrics = metric_set(accuracy, roc_auc) # Métricas de evaluación.\n        ) \n    \n    # Visualizamos los resultados de la validación cruzada.\n        autoplot(modelos_entrenados) \n    ```\n    \n    ::: {.cell-output-display}\n    ![](07-redes-neuronales_files/figure-html/unnamed-chunk-15-1.png){width=672}\n    :::\n    :::\n\n    :::\n\na.  Seleccionar el mejor modelo según la exactitud y entrenarlo con el conjunto de entrenamiento.\n    \n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    modelo_final <- flujo |>\n        # Seleccionamos el mejor modelo según la exactitud.\n        finalize_workflow(select_best(modelos_entrenados, metric = \"accuracy\")) |> \n        # Entrenamos el modelo con el conjunto de entrenamiento.\n        last_fit(df_particion, metrics = metric_set(accuracy, roc_auc))\n    # Mostramos un resumen del modelo.\n    modelo_final |>\n        extract_fit_engine() \n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    Multilayer perceptron\n    \n    relu activation,\n    25 hidden units,\n    506 model parameters\n    4,255 samples, 13 features, 6 classes \n    class weights Muy malo=1, Malo=1, Regular=1, Bueno=1, Muy bueno=1, Excelente=1 \n    weight decay: 0.001 \n    dropout proportion: 0 \n    batch size: 3830 \n    learn rate: 0.01 \n    validation loss after 13 epochs: 0.874 \n    ```\n    \n    \n    :::\n    :::\n\n    :::\n\na.  Evaluar el modelo con el conjunto de test y la exactitud y el área bajo la curva ROC.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Extraemos las métricas de evaluación del modelo entrenado.\n        collect_metrics(modelo_final) |> kable()\n    ```\n    \n    ::: {.cell-output-display}\n    \n    \n    |.metric  |.estimator | .estimate|.config              |\n    |:--------|:----------|---------:|:--------------------|\n    |accuracy |multiclass | 0.6018779|Preprocessor1_Model1 |\n    |roc_auc  |hand_till  | 0.8050608|Preprocessor1_Model1 |\n    \n    \n    :::\n    :::\n\n    :::\n:::\n\n## Ejercicios Propuestos\n\n:::{#exr-redes-neuronales-infartos}\nEl fichero [`infartos.csv`](datos/infartos.csv) contiene información sobre distintas variables fisiológicas relacionadas con el riesgo de infarto de una muestra de personas. Las variables que contienen son:\n\n- `Edad`: Edad del paciente (años)\n- `Sexo`: Sexo del paciente (H: hombre, M: mujer)\n- `DolorPecho`: Tipo de dolor torácico (TA: angina típica, ATA: angina atípica, NAP: dolor no anginoso, ASY: asintomático)\n- `PresionArterial`: Presión arterial sistólica en reposo (mm Hg)\n- `Colesterol`: Colesterol sérico (mm/dl)\n-  `Glucemia`: Glucemia en ayunas (1: si glucemia en ayunas > 120 mg/dl, 0: de lo contrario)\n- `Electro`: resultados del electrocardiograma en reposo (Normal: normal, ST: anomalía onda ST-T (inversiones de onda T y/o elevación o depresión de ST > 0,05 mV), LVH: hipertrofia ventricular izquierda probable o definitiva según criterios de Estes)\n- `Pulsaciones`: Frecuencia cardíaca máxima alcanzada (valor numérico entre 60 y 202)\n- `AnginaEjercicio`: Angina inducida por ejercicio (S: sí, N: no)\n- `DepresionST`: Depresión del segmento ST inducida por el ejercicio (valor numérico de la depresión).\n- `PendienteST`: Pendiente del segmento ST en el pico de ejercicio (Ascendente, Plano, Descencdente).\n- `Infarto`: Riesgo de infarto (1: Sí, 0: No)\n\na.  Crear un dataframe con los datos del archivo [`infartos.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/vinos.csv).\n\na.  Realizar un análisis exploratorio de los datos.\n\na.  Dividir el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test. Utilizar el 80% de los datos para entrenamiento y el 20% restante para test.\n\na.  Construir una red neuronal para predecir el riesgo de infarto explorando distinto número de neuronas en la capa oculta y validando los modelos mediante validación cruzada de 5 pliegues. ¿Qué número de neuronas tiene el mejor modelo según la exactitud?\n\na.  Entrenar el mejor modelo del apartado anterior con el conjunto de entrenamiento y evaluarlo con el conjunto de test. Calcular la matriz de confusión y también la precisión, sensibilidad y la especificidad.\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}