---
title: Aprendizaje no supervisado
lang: es
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

El aprendizaje no supervisado abarca técnicas de aprendizaje automático que buscan identificar patrones en los datos sin utilizar clases o categorías predefinidas. A diferencia del aprendizaje supervisado, donde se entrena un modelo con datos etiquetados, el aprendizaje no supervisado no busca clasificar o predecir una variable respuesta, sino que se centra en descubrir estructuras ocultas en los datos. En esta práctica, exploraremos dos técnicas comunes de aprendizaje no supervisado: el análisis de componentes principales (PCA) que consiste en buscar una representación de los datos en un espacio de menor dimensión preservando la mayor cantidad de varianza posible, y el agrupamiento (clustering) que busca agrupar los datos en grupos similares basándose en sus características. Estas técnicas son útiles para la exploración de datos, la reducción de dimensionalidad y la identificación de patrones subyacentes en conjuntos de datos complejos.

## Ejercicios Resueltos

Para la realización de esta práctica se requieren los siguientes paquetes:

```r
library(tidyverse) 
# Incluye los siguientes paquetes:
# - readr: para la lectura de ficheros csv. 
# - dplyr: para el preprocesamiento y manipulación de datos.
# - ggplot2: para la visualización de datos.
library(tidymodels)
# Incluye los siguientes paquetes:
# - recipes: para la preparación de los datos. 
# - parsnip: para la creación de modelos.
# - workflows: para la creación de flujos de trabajo.
# - rsample: para la creación de particiones de los datos.
# - yardstick: para la evaluación de modelos.
# - tune: para la optimización de hiperparámetros.
library(skimr) # para el análisis exploratorio de datos.
library(GGally) # para la visualización de matrices de correlación.
library(FactoMineR) # para el análisis de componentes principales.
library(factoextra) # para dibujar los componentes principales.
library(psych) # para el cálculo de la kappa de Cohen.
library(plotly) # para la visualización interactiva de gráficos.
library(knitr) # para el formateo de tablas.
```

::: {#exr-no-supervisado-pinguinos}
El conjunto de datos [pingüinos.csv](datos/pingüinos.csv) contiene un conjunto de datos sobre tres especies de pingüinos con las siguientes variables:

- Especie: Especie de pingüino (Adelie, Chinstrap o Gentoo).
- Isla: Isla del archipiélago Palmer donde se realizó la observación.
- Longitud_pico: Longitud del pico (mm).
- Profundidad_pico: Profundidad del pico (mm)
- Longitud_ala: Longitud de la aleta en (mm).
- Peso: Masa corporal (g).
- Sexo: Sexo (macho, hembra)

a.  Cargar los datos del archivo [`pingüinos.csv`](datos/pingüinos.csv) en un data frame.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(tidyverse)
    # Cargamos el conjunto de datos en un data frame.
    df <- read.csv("https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/pingüinos.csv", stringsAsFactors = TRUE)
    # Mostramos un resumen del data frame.
    glimpse(df)
    ```
    :::

a.  Realizar un análisis exploratorio de los datos.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(skimr)
    # Análisis exploratorio de los datos.
    skim(df) 
    ```
    :::

a.  Eliminar del data frame las columnas `Isla`, `Sexo` y `Peso` y eliminar las filas con valores perdidos.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    # Eliminamos las columnas Isla, Sexo y Peso.
    df <- df |> select(-Isla, -Sexo, -Peso) |>
        # Eliminamos las filas con valores perdidos.
        drop_na()
    ```
    :::

a.  Realizar un análisis de correlación entre las variables numéricas del conjunto de datos.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`ggcorr`](https://ggobi.github.io/ggally/reference/ggcorr.html) del paquete [`GGally`](https://ggobi.github.io/ggally/) para dibujar un diagrama de correlación entre las variables numéricas del conjunto de datos. 
    
    Parámetros:
    - `label = TRUE` para mostrar las etiquetas de correlación.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(GGally)
    ggcorr(df, label = TRUE)
    ```
    :::

a.  Realizar un diagrama de dispersión tridimensional de las variables `Longitud_pico`, `Profundidad_pico` y `Longitud_ala` coloreando los puntos según la especie de pingüino.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`plot_ly`](https://plotly.com/r/reference/#scatter3d) del paquete [`plotly`](https://plotly.com/r/) para dibujar un diagrama de dispersión tridimensional.
    
    Parámetros:
    - `x = Longitud_pico`, `y = Profundidad_pico`, `z = Longitud_ala` para indicar las variables a utilizar.
    - `color = Especie` para colorear los puntos según la especie de pingüino.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(plotly)
    # Diagrama de dispersión tridimensional de las variables Longitud_pico, Profundidad_pico y Longitud_ala. Coloreamos los puntos según la especie de pingüino.
    df |> plot_ly(x = ~Longitud_pico, y = ~Profundidad_pico, z = ~Longitud_ala, 
            color = ~Especie,
            type = "scatter3d", mode = "markers") |>
        layout(title = "Diagrama de dispersión tridimensional de pingüinos",
            scene = list(xaxis = list(title = "Longitud del Pico (mm)"),
                            yaxis = list(title = "Profundidad del Pico (mm)"),
                            zaxis = list(title = "Longitud de la Aleta (mm)")))
    ```
    :::

a.  Calcular los componentes principales del conjunto de variables numéricas y mostrar la varianza explicada por cada componente.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`PCA`](https://www.rdocumentation.org/packages/FactoMineR/topics/PCA) del paquete [`FactoMineR`](http://factominer.free.fr/) para obtener los componentes principales del conjunto de variables numéricas.
    
    Parámetros:
    - `scale.unit = TRUE` para normalizar las variables.
    - `ncp = n` para obtener los primeros n componentes principales.

    O bien utilizar la función [`recipe`](https://recipes.tidymodels.org/reference/recipe.html) del paquete [recipes](https://recipes.tidymodels.org/) incluido en la colección de paquetes [`tidymodels`](https://www.tidymodels.org/) para crear una receta de preprocesamiento. 
    
    Parmámetros:
    - `~.` para indicar que se deben utilizar todas las variables.
  
    Después, utilizar la función [`step_pca`](https://recipes.tidymodels.org/reference/step_pca.html) para calcular los componentes principales.
    
    Parámetros:
    - `all_numeric_predictors()` para indicar que se deben utilizar todas las variables numéricas.
    - `threshold = 0.95` para indicar el umbral de varianza explicada por los componentes principales. Esto significa que se seleccionarán los componentes principales que expliquen al menos el 95% de la varianza total.
    - `num_comp = n` para indicar el número de componentes principales a calcular.

    Previamente es recomendable normalizar las variables numéricas con la función [`step_normalize`](https://recipes.tidymodels.org/reference/step_normalize.html).
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    :::{.panel-tabset}
    ## `FactoMinerR

    ```{r}
    library(FactoMineR)
    library(knitr)
    # Seleccionamos las variables numéricas.
    componentes <- df |> select(where(is.numeric)) |>
        # Calculamos los componentes principales.
        PCA(scale.unit = TRUE, graph = FALSE)   

    # Mostramos los autovalores y varianza explicada.
    kable(componentes$eig)

    # Dibujamos un gráfico de la varianza explicada
    library(factoextra)
    fviz_eig(componentes, addlabels = TRUE)
    ```

    ## `tidymodels`

    ```{r}
    library(tidymodels)
    # Creamos una receta de preprocesamiento.
    receta <- df |> recipe(~ .) |>
        # Normalizamos las variables numéricas.
        step_normalize(all_numeric_predictors()) |>
        # Calculamos los componentes principales con un umbral de varianza del 95%.
        step_pca(all_numeric_predictors(), threshold = 0.95, id = "pca") |>
        # Estimamos los parámetros necesarios para aplicar la receta.
        prep()

    # Obtenemos la varianza explicada con cada componente principal.
    receta |> tidy(id = "pca", type = "variance") |> 
        # Filtramos los términos para quedarnos con el porcentaje de varianza.
        filter(terms == "percent variance") |> 
        # Dibujamos un diagrama de barras de la varianza explicada.
        ggplot(aes(x = `component`, y = value)) +
        geom_col() +
        labs(title = "Varianza explicada por los componentes principales",
            x = "Componentes Principales",
            y = "Porcentaje de Varianza") 

    # Aplicamos la receta a los datos.
    df_componentes <- receta |> bake(new_data = NULL)
    ```
    :::
    :::

a.  Mostrar los autovectores

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`get_pca_var`](https://rpkgs.datanovia.com/factoextra/reference/get_pca.html) del paquete [`factoextra`](https://rpkgs.datanovia.com/factoextra/index.html) para obtener los autovectores de los componentes principales.
    
    Parámetros:
    - `componentes` para indicar el objeto con los componentes principales.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    # Obtenemos los autovectores. 
    autovectores <- get_pca_var(componentes)
    kable(autovectores$coord)

    # Gráfico de los autovectores
    fviz_pca_var(componentes, col.var = "contrib")
    ```
    :::

a.  Dibujar un gráfico de dispersión de los dos primeros componentes principales coloreando los puntos según la especie de pingüino.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`fviz_pca_ind`](https://rpkgs.datanovia.com/factoextra/reference/get_pca.html) del paquete [`factoextra`](https://rpkgs.datanovia.com/factoextra/index.html) para dibujar un gráfico de dispersión de los dos primeros componentes principales.
    
    Parámetros:
    - `componentes` para indicar el objeto con los componentes principales.
    - `col.ind = df$Especie` para colorear los puntos según la especie de pingüino.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    :::{.panel-tabset}

    ## `factoextra`

    ```{r}
    # Diagrama de dispersión de los dos primeros componentes principales.
    grafico <- componentes |> fviz_pca_ind(col.ind = df$Especie, label = "none") +
        labs(title = "Diagrama de dispersión de los dos primeros componentes principales según Especie",
            x = "Componente Principal 1",
            y = "Componente Principal 2")
    # Convertimos el gráfico en interactivo.
    ggplotly(grafico) 
    ```

    ## `ggplot2`

    ```{r}
    # Diagrama de dispersión de los dos primeros componentes principales.
    grafico <- df_componentes  |>  ggplot(aes(x = PC1, y = PC2, color = Especie)) +
        geom_point() +
        labs(title = "Diagrama de dispersión de los dos primeros componentes principales según Especie",
            x = "Componente Principal 1",
            y = "Componente Principal 2")
    # Convertimos el gráfico a interactivo
    ggplotly(grafico)
    ```
    :::
    :::

a.  Realizar un agrupamiento en grupos utilizando el método de las $k$-medias y representar los grupos en un diagrama de dispersión.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`fviz_nbclust`](https://rpkgs.datanovia.com/factoextra/reference/fviz_nbclust.html) del paquete [`factoextra`](https://rpkgs.datanovia.com/factoextra/index.html) para determinar el número óptimo de grupos.

    Parámetros:
    - `kmeans` para utilizar el método de las $k$-medias.
    - `method = "wss"` para utilizar el método del codo (within-cluster sum of squares).
  
    Después, utilizar la función [`kmeans`](https://www.rdocumentation.org/packages/stats/topics/kmeans) del paquete `stats` para realizar el agrupamiento en grupos.

    Parámetros:
    - `centers = n` para indicar el número de grupos a crear.

    O bien utilizar la funicón [`k_means`](https://tidyclust.tidymodels.org/reference/k_means.html) del paquete [`tidyclust`](https://tidyclust.tidymodels.org/index.html) para especificar un modelo de[`tidymodels`](https://www.tidymodels.org/) para realizar el agrupamiento en grupos.

    Parámetros:
    - `num_clusters = n` para indicar el número de grupos a crear.

    Usar después la función [`augment`](https://parsnip.tidymodels.org/reference/augment.html) del paquete [`parsnip`](https://parsnip.tidymodels.org/index.html) para obtener el grupo asignado a cada pingüino.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    :::{.panel-tabset}

    ## `stats`

    ```{r}
    # Establecemos una semilla para la reproducibilidad.
    set.seed(123)

    # Seleccionamos las variables numéricas.
    df |> select(where(is.numeric)) |>
        # Determinamos el número óptimo de grupos.
        fviz_nbclust(kmeans, method = "wss")
    ```

    A la vista del gráfico anterior, el número óptimo de grupos, donde se ubica el "codo" del gráfico, sería 3 o 4, lo que se corresponde con las 3 especies de pingüinos.

    ```{r}
    # Seleccionamos las variables numéricas.
    agrupacion <- df |> select(where(is.numeric)) |> 
        # Realizamos el agrupamiento en 3 grupos.
        kmeans(centers = 3)

    # Añadimos los grupos al data frame original.
    df$Grupo <- as.factor(agrupacion$cluster)

    # Dibujamos un diagrama de dispersión de los dos primeros componentes principales coloreando los puntos según el grupo.
    componentes |> fviz_pca_ind(col.ind = df$Grupo, label = "none") +
        labs(title = "Diagrama de dispersión de los dos primeros componentes principales según Grupo",
            x = "Componente Principal 1",
            y = "Componente Principal 2")
    ```

    ## `tidymodels`

    ```{r}
    library(tidyclust)
    # Establecemos una semilla para la reproducibilidad.
    set.seed(123)
    # Creamos un modelo de agrupamiento en 3 grupos.
    modelo_ajustado <- k_means(num_clusters = 3) |>
        # Especificamos el motor a utilizar.
        set_engine("stats") |> 
        # Ajustamos el modelo a los datos.
        fit(~., data = df)

    # Creamos un nuevo data frame con los datos del conjunto de datos original y los grupos asignados.
    df_grupos <- modelo_ajustado |> augment(df)
    # Mostramos el data frame con los grupos asignados.
    df_grupos |> head() |> 
        kable()
    ```

    ```{r}
    # Creamos un data frame con lo valores de los componentes principales y el grupo asignado.
    df_componentes <- df_componentes |> 
        mutate(Grupo = df_grupos$.pred_cluster)

    # Dibujamos un diagrama de dispersión de los dos primeros componentes principales coloreando los puntos según el grupo.
    df_componentes |> 
        ggplot(aes(x = PC1, y = PC2, color = Grupo)) +
        geom_point() +
        labs(title = "Diagrama de dispersión de los dos primeros componentes principales según Grupo",
            x = "Componente Principal 1",
            y = "Componente Principal 2")
    ```
    :::
    :::

a.  Obtener una tabla de contingencia para ver la relación entre las especies de pingüinos y los grupos obtenidos.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    # Creamos una tabla de contingencia con la Especie en las filas y el Grupo en las columnas.
    table(df$Especie, df$Grupo) |> 
        kable()
    ```
    :::

a.  Calcular la kappa de Cohen para ver la concordancia entre las especies de pingüinos y los grupos obtenidos.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`cohen.kappa`](https://www.rdocumentation.org/packages/irr/topics/cohen.kappa) del paquete `irr` para calcular la kappa de Cohen.
    
    Parámetros:
    - `cbind(df$Especie, df$Grupo)` dataframe con las dos variables a comparar.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(psych)
    # Calculamos la kappa de Cohen.
    cohen.kappa(cbind(df$Especie, df$Grupo)) |> 
        tidy() |>
        kable()
    ```
    :::

a.  Realizar un análisis de agrupamiento jerárquico de las especies de pingüinos y dibujar el dendograma asociado coloreando los puntos según la especie de pingüino.

    :::{.callout-note collapse="true"}
    ## Ayuda
    Utilizar la función [`hclust`](https://www.rdocumentation.org/packages/stats/topics/hclust) del paquete `stats` para realizar el análisis de agrupamiento jerárquico.

    Parámetros:
    - `dist` para calcular la matriz de distancias entre las observaciones.
    - `method = "complete"` para utilizar el método de enlace completo.
    
    Utilizar la función [`fviz_dend`](https://rpkgs.datanovia.com/factoextra/reference/fviz_dend.html) del paquete [`factoextra`](https://rpkgs.datanovia.com/factoextra/index.html) para dibujar el dendograma.

    Parámetros:
    - `k = n` para crear n grupos.
    - `color_labels_by_k = TRUE` para colorear las etiquetas según el grupo.
    - `rect = TRUE` para dibujar rectángulos alrededor de los grupos.
    - `rect_fill = TRUE` para rellenar los rectángulos.
    :::

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    # Calculamos la matriz de distancias.
    distancias <- df |> select(where(is.numeric)) |> 
        dist(method = "euclidean")
    # Realizamos el agrupamiento jerárquico.    
    jerarquia <- hclust(distancias, method = "complete")
    # Dibujamos un dendrograma coloreado por especie.
    fviz_dend(jerarquia, 
        k = 3,  # número de grupos
        color_labels_by_k = TRUE,
        rect = TRUE,
        rect_fill = TRUE) +
    labs(title = "Dendrograma de agrupamiento Jerárquico de Pingüinos")
    ```
    :::
:::

:::{#exr-no-supervisado-glaucoma}
El conjunto de datos [glaucoma.csv](datos/glaucoma.csv) contiene información sobre el grosor de los sectores de los anillos peripalilares de la capa de fibras nerviosas de la retina obtenidos mediante tomografía de coherencia óptica (OTC) en pacientes con y sin glaucoma. En la OTC se toman 4 anillos con distintos radios (BMO, 3.5 mm, 4.1 mm y 4.7 mm) y para cada anillo se miden 6 sectores (Nasal Superior, Nasal, Nasal Inferior, Temporal Inferior, Temporal y Temporal Superior) y también la media global. Los datos están ya normalizados.

![Tomografía de coherencia óptica](/img/aprendizaje-no-supervisado/tomografia-coherencia-optica.jpg)

a.  Cargar el conjunto de datos del archivo [`glaucoma.csv`](datos/glaucoma.csv) en un data frame.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(tidyverse)
    # Cargamos el conjunto de datos en un data frame.
    df <- read.csv("https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/glaucoma.csv", stringsAsFactors = TRUE)
    # Mostramos un resumen del data frame.
    glimpse(df)
    ```
    :::

a.  Realizar un análisis exploratorio de los datos.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(skimr)
    # Análisis exploratorio de los datos.
    skim(df)
    ```
    :::

a.  Estudiar la correlación entre las variables numéricas del conjunto de datos.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(GGally)
    # Seleccionamos las variables numéricas (son las que empiezan por "Anillo").
    df |> select(starts_with("Anillo")) |>
        # Diagrama de correlación entre las variables numéricas.
        ggcorr(label = TRUE, label_size = 3)
    ```
    :::

a.  Calcular los componentes principales del conjunto de variables numéricas y mostrar la varianza explicada por cada componente.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(FactoMineR)
    # Seleccionamos las variables numéricas (son las que empiezan por "Anillo").
    componentes <- df |> select(starts_with("Anillo")) |>
        # Calculamos los componentes principales.
        PCA(graph = FALSE)   

    # Mostramos los autovalores y varianza explicada.
    kable(componentes$eig)

    # Dibujamos un gráfico de la varianza explicada
    library(factoextra)
    fviz_eig(componentes, addlabels = TRUE)
    ```
    :::

a.  Dibujar un diagrama de dispersión de los dos primeros componentes principales coloreando los puntos según el diagnóstico de glaucoma.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    library(plotly)
    # Dibujamos el diagrama de dispersión de los dos primeros componentes principales.
    plot <- componentes |> fviz_pca_ind(col.ind = df$Glaucoma, label = "none") +
        labs(title = "Gráfico de dispersión de los dos primeros componentes principales",
            x = "Componente Principal 1",
            y = "Componente Principal 2")
    ggplotly(plot) # Convertimos el gráfico a interactivo
    ```
    :::

a.  Realizar un agrupamiento en grupos utilizando el método de las $k$-medias y representar los grupos en un diagrama de dispersión.

    :::{.callout-tip collapse="true"}
    ## Solución

    ```{r}
    # Establecemos una semilla para la reproducibilidad.
    set.seed(123)
    # Filtramos los datos para quedarnos solo con los pacientes con glaucoma.
    df |> filter(Glaucoma == "Sí") |> 
        # Seleccionamos las variables numéricas (son las que empiezan por "Anillo").
        select(starts_with("Anillo")) |>
        # Determinamos el número óptimo de grupos utilizando las distancias dentro de cada grupo al cuadrado.
        fviz_nbclust(kmeans, method = "wss")
    ```

    A la vista del gráfico anterior, el número óptimo de grupos, donde se ubica el "codo" del gráfico, sería 3 o 4.

    ```{r}
    # Filtramos los datos para quedarnos solo con los pacientes con glaucoma.
    agrupacion <- df |> filter(Glaucoma == "Sí") |> 
        # Seleccionamos las variables numéricas (son las que empiezan por "Anillo").
        select(starts_with("Anillo")) |>
        # Realizamos el agrupamiento en 4 grupos.
        kmeans(centers = 4)
    # Extraemos los centroides de los grupos y los ordenamos de mayor a menor por la primera componente.    
    centroides <- agrupacion$centers[order(agrupacion$centers[,1], decreasing = T),]
    # Filtramos de nuevo para quedarnos solo con los pacientes con glaucoma.
    agrupacion <- df |> filter(Glaucoma == "Sí") |> 
        # Seleccionamos las variables numéricas (son las que empiezan por "Anillo").
        select(starts_with("Anillo")) |>
        # Volvemos a realizar el agrupamiento en 4 grupos, pero ahora partiendo de los centroides ordenados.
        kmeans(centers = centroides)
    # Convertimos los grupos en un factor.
    agrupacion$cluster <- as.factor(agrupacion$cluster)
    # Asignamos etiquetas a los niveles del factor.
    labels <- c("I", "II", "III", "IV")
    levels(agrupacion$cluster) <- labels
    # Creamos un data frame de los pacientes con glaucoma y le añadimos los grupos.
    df_glaucoma <- df |> filter(Glaucoma == "Sí") |> 
        mutate(Estadio = agrupacion$cluster)
    # Filtramos el data frame original para quedarnos solo con los pacientes sin glaucoma.
    df <- df |> filter(Glaucoma == "No") |> 
        # Añadimos al data frame original una nueva columna con el Estadio de glaucoma.
        mutate(Estadio = "Sano") |> 
        # Unimos los data frames de pacientes con y sin glaucoma.
        bind_rows(df_glaucoma)

    # Dibujamos un diagrama de dispersión de los dos primeros componentes principales coloreando los puntos según el estadio de glaucoma. Añadimos elipses alrededor de los grupos.
    plot <- componentes |> fviz_pca_ind(col.ind = df$Estadio, label = "none", addEllipses = T) +
        labs(title = "Gráfico de dispersión de los dos primeros componentes principales según estadio de Glaucoma")
    ggplotly(plot)
    ```
    :::
:::


## Ejercicios propuestos

:::{#exr-no-supervisado-cancer-mama}
El conjunto de datos [cancer-mama.csv](datos/cancer-mama.csv) contiene información sobre las características de núcleos de células mamarias obtenidas de imágenes digitalizadas tanto de células cancerosas como no cancerosas obtenidas por biopsia. Las variables que contiene son:

- ID: Identificador único de la muestra.
- Diagnóstico: Diagnóstico de la muestra (M: maligno, B: benigno).
- Radio: Media de la distancia desde el centro hasta los puntos de la superficie.
- Textura: Desviación estándar de la intensidad de gris de los puntos.
- Perímetro: Longitud del contorno.
- Área: Área de la imagen.
- Suavidad: Variación local en la longitud del radio.
- Compacidad: Perímetro^2 / Área - 1.0.
- Concavidad: Magnitud de las porciones cóncavas del contorno.
- Puntos_concavos: Número de puntos cóncavos del contorno.
- Simetría: Simetría de la imagen.
- Irregularidad: Medida de la irregularidad de la forma.

a.  Crear un dataframe con los datos del archivo [`cancer-mama.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/cancer-mama.csv).

a.  Realizar un análisis exploratorio de los datos.

a.  Dibujar un diagrama de correlación entre las variables numéricas del conjunto de datos.

a.  Calcular los componentes principales del conjunto de variables numéricas.

a.  Dibujar un diagrama de barras con la varianza explicada por cada componente principal.

a.  Dibujar un diagrama de dispersión de los dos primeros componentes principales coloreando los puntos según el diagnóstico.

a.  Realizar un agrupamiento en grupos utilizando el método de las $k$-medias y representar los grupos en un diagrama de dispersión.
:::

:::{#exr-no-supervisado-vinos}
El fichero [`vinos.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/vinos.csv) contiene información sobre las características de vinos blancos y tintos portugueses de la denominación "Vinho Verde". Las variables que contiene son las siguientes:

| Variable             | Descripción                                                           | Tipo (unidades)        |
|----------------------------------------|-----------------------------------------------------------------------|------------------------|
| tipo                 | Tipo de vino                                                          | Factor (blanco, tinto) |
| meses.barrica        | Meses de envejecimiento en barrica                               | Numérica(meses)  |
| acided.fija          | Cantidad de ácidotartárico                                 | Numérica(g/dm3)  |
| acided.volatil       | Cantidad de ácido acético                                             | Numérica(g/dm3)  |
| acido.citrico        | Cantidad de ácidocítrico                                        | Numérica(g/dm3)  |
| azucar.residual      | Cantidad de azúcar remanente después de la fermentación          | Numérica(g/dm3)  |
| cloruro.sodico       | Cantidad de clorurosódico                                       | Numérica(g/dm3)  |
| dioxido.azufre.libre | Cantidad de dióxido de azufre en forma libre                | Numérica(mg/dm3) |
| dioxido.azufre.total | Cantidad de dióxido de azufre total en forma libre o ligada | Numérica(mg/dm3) |
| densidad             | Densidad                                                              | Numérica(g/cm3)  |
| ph                   | pH                                                                    | Numérica(0-14)   |
| sulfatos             | Cantidad de sulfato de potasio                                   | Numérica(g/dm3)  |
| alcohol              | Porcentaje de contenido de alcohol                          | Numérica(0-100)  |
| calidad              | Calificación otorgada por un panel de expertos                   | Numérica(0-10)   |

a.  Crear un dataframe con los datos del archivo [`vinos.csv`](https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/vinos.csv).

a.  Realizar un análisis exploratorio de los datos.

a.  Dibujar un diagrama de correlación entre las variables numéricas del conjunto de datos.

a.  Calcular los componentes principales del conjunto de variables numéricas químicas.

a.  Dibujar un diagrama de barras con la varianza explicada por cada componente principal.

a.  Dibujar un diagrama de dispersión de los dos primeros componentes principales coloreando los puntos según el tipo de vino. Repetir el diagrama de dispersión coloreando los puntos según el envejecimiento del vino.

a.  Realizar un agrupamiento en grupos utilizando el método de las $k$-medias y representar los grupos en un diagrama de dispersión.
:::