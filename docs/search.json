[
  {
    "objectID": "07-redes-neuronales.html",
    "href": "07-redes-neuronales.html",
    "title": "7  Redes Neuronales",
    "section": "",
    "text": "7.1 Ejercicios Resueltos\nLas redes de neuronas artificiales son un modelo computacional inspirado en el funcionamiento del cerebro humano. Una neurona artificial es una unidad de cómputo bastante simple, que recibe una serie de entradas, las procesa y produce una salida. La salida de una neurona puede ser la entrada de otra neurona, formando así una red de neuronas interconectadas, donde cada conexión tiene un peso asociado. Es esta red, que a veces contiene miles y millones de neuronas, la que dota de gran potencia de cálculo a este modelo, siendo capaces de aprender patrones de datos muy complejos, como imágenes, texto o sonido, y por tanto, se utilizan a menudo en tareas de clasificación o regresión.\nEl aprendizaje en una red neuronal consiste en ajustar los pesos de las conexiones para minimizar el error entre la salida predicha y la salida real.\nPara la realización de esta práctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "07-redes-neuronales.html#ejercicios-resueltos",
    "href": "07-redes-neuronales.html#ejercicios-resueltos",
    "title": "7  Redes Neuronales",
    "section": "",
    "text": "library(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - ggplot2: para la visualización de datos.\nlibrary(tidymodels)\n# Incluye los siguientes paquetes:\n# - recipes: para la preparación de los datos. \n# - parsnip: para la creación de modelos.\n# - workflows: para la creación de flujos de trabajo.\n# - rsample: para la creación de particiones de los datos.\n# - yardstick: para la evaluación de modelos.\n# - tune: para la optimización de hiperparámetros.\nlibrary(skimr) # para el análisis exploratorio de datos.\nlibrary(brulee) # Para entrenar redes neuronales con `torch`.\nlibrary(knitr) # para el formateo de tablas.\n\nEjercicio 7.1 El conjunto de datos cancer-mama.csv contiene información sobre las características de núcleos de células mamarias obtenidas de imágenes digitalizadas tanto de células cancerosas como no cancerosas obtenidas por biopsia. Las variables que contiene son:\n\nID: Identificador único de la muestra.\nDiagnostico: Diagnóstico de la muestra (M: maligno, B: benigno).\nRadio: Media de la distancia desde el centro hasta los puntos de la superficie.\nTextura: Desviación estándar de la intensidad de gris de los puntos.\nPerímetro: Longitud del contorno.\nÁrea: Área de la imagen.\nSuavidad: Variación local en la longitud del radio.\nCompacidad: Perímetro^2 / Área - 1.0.\nConcavidad: Magnitud de las porciones cóncavas del contorno.\nPuntos_concavos: Número de puntos cóncavos del contorno.\nSimetría: Simetría de la imagen.\nIrregularidad: Medida de la irregularidad de la forma.\n\n\nCrear un dataframe con los datos del archivo cancer-mama.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- read.csv(\"https://aprendeconalf.es/aprendizaje-automatico-practicas-r/datos/cancer-mama.csv\", stringsAsFactors = TRUE) |&gt;\n    # Convertimos la variable Diagnostico a un factor.\n    mutate(Diagnostico = factor(Diagnostico, levels = c(\"B\", \"M\"), labels = c(\"Benigno\", \"Maligno\")))\nglimpse(df)\n\nRows: 569\nColumns: 12\n$ ID              &lt;int&gt; 842302, 842517, 84300903, 84348301, 84358402, 843786, …\n$ Diagnostico     &lt;fct&gt; Maligno, Maligno, Maligno, Maligno, Maligno, Maligno, …\n$ Radio           &lt;dbl&gt; 17.990, 20.570, 19.690, 11.420, 20.290, 12.450, 18.250…\n$ Textura         &lt;dbl&gt; 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.98, 20.83…\n$ Perimetro       &lt;dbl&gt; 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, 119.60, …\n$ Area            &lt;dbl&gt; 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, 1040.0, …\n$ Suavidad        &lt;dbl&gt; 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0.12780, …\n$ Compacidad      &lt;dbl&gt; 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0.17000, …\n$ Concavidad      &lt;dbl&gt; 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0.15780, …\n$ Puntos_Concavos &lt;dbl&gt; 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0.08089, …\n$ Simetria        &lt;dbl&gt; 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087, 0.1794…\n$ Irregularidad   &lt;dbl&gt; 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0.07613, …\n\n\n\n\n\nHacer un análisis exploratorio de los datos.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(skimr)\nskim(df)\n\n\nData summary\n\n\nName\ndf\n\n\nNumber of rows\n569\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nDiagnostico\n0\n1\nFALSE\n2\nBen: 357, Mal: 212\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nID\n0\n1\n30371831.43\n125020585.61\n8670.00\n869218.00\n906024.00\n8813129.00\n911320502.00\n▇▁▁▁▁\n\n\nRadio\n0\n1\n14.13\n3.52\n6.98\n11.70\n13.37\n15.78\n28.11\n▂▇▃▁▁\n\n\nTextura\n0\n1\n19.29\n4.30\n9.71\n16.17\n18.84\n21.80\n39.28\n▃▇▃▁▁\n\n\nPerimetro\n0\n1\n91.97\n24.30\n43.79\n75.17\n86.24\n104.10\n188.50\n▃▇▃▁▁\n\n\nArea\n0\n1\n654.89\n351.91\n143.50\n420.30\n551.10\n782.70\n2501.00\n▇▃▂▁▁\n\n\nSuavidad\n0\n1\n0.10\n0.01\n0.05\n0.09\n0.10\n0.11\n0.16\n▁▇▇▁▁\n\n\nCompacidad\n0\n1\n0.10\n0.05\n0.02\n0.06\n0.09\n0.13\n0.35\n▇▇▂▁▁\n\n\nConcavidad\n0\n1\n0.09\n0.08\n0.00\n0.03\n0.06\n0.13\n0.43\n▇▃▂▁▁\n\n\nPuntos_Concavos\n0\n1\n0.05\n0.04\n0.00\n0.02\n0.03\n0.07\n0.20\n▇▃▂▁▁\n\n\nSimetria\n0\n1\n0.18\n0.03\n0.11\n0.16\n0.18\n0.20\n0.30\n▁▇▅▁▁\n\n\nIrregularidad\n0\n1\n0.06\n0.01\n0.05\n0.06\n0.06\n0.07\n0.10\n▆▇▂▁▁\n\n\n\n\n\n\n\n\nDibujar un diagrama de relación entre todos los pares de variables del conjunto de datos diferenciando por el diagnóstico.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nSe puede utilizar la función ggpairs del paquete GGally para dibujar un diagrama de relación entre todos los pares de variables del conjunto de datos. Asociar el sexo a la dimensión del color.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(GGally)\nggpairs(df, aes(color = Diagnostico, alpha = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nDividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba, con una proporción del 80% para el entrenamiento y el 20% para la prueba, estratificando por el diagnóstico.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la función initial_split del paquete rsample para dividir el conjunto de datos en entrenamiento y test.\nParámetros:\n\ndata: el data frame con los datos.\nprop: la proporción del conjunto de datos que se utilizará para el conjunto de entrenamiento (en este caso, 0.8 para el 80%).\nstrata: la variable de estratificación (en este caso, Diagnostico) para asegurar que la distribución de clases se mantenga en ambos conjuntos.\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidymodels)\n# Establecemos la semilla para la reproducibilidad.\nset.seed(123)\n# Dividimos el conjunto de datos en un conjunto de entrenamiento y un conjunto de test.\ndf_particion &lt;- initial_split(df, prop = 0.8, strata = \"Diagnostico\")\n# Extraemos el conjunto de entrenamiento.\ndf_entrenamiento &lt;- training(df_particion)\n# Extraemos el conjunto de test.\ndf_test &lt;- testing(df_particion)\n\n\n\n\nPreprocesar el conjunto de entrenamiento convertir la variable respuesta, el diagnóstico, en una variable numérica y normalizar el resto de variables predictivas\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Creamos una receta de preprocesamiento.\nreceta &lt;- recipe(Diagnostico ~ ., data = df_entrenamiento) |&gt;\n    # Convertimos la variable respuesta en una variable numérica.\n    #step_dummy(Diagnostico) |&gt;\n    # Normalizamos las variables numéricas.\n    step_normalize(all_numeric_predictors())\n\n\n\n\nConstruir una red neuronal con una capa oculta de 10 neuronas para predecir el diagnóstico.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la función mlp del paquete parsnip para crear un modelo de red neuronal.\nParámetros:\n\nhidden_units: el número de neuronas en la capa oculta (10 en este caso).\nactivation: la función de activación a utilizar (por defecto “relu”).\ndropout: la proporción de parámetros reseteados a 0 durante el entrenamiento (0.1 por defecto).\nepochs: el número de épocas de entrenamiento (100 por defecto).\n\nDespués, utilizar la función set_engine para especificar el motor a utilizar (en este caso, brulee).\nUtilizar la función set_mode para especificar que se trata de un modelo de clasificación.\nFinalmente, utilizar la función extract_fit_engine para extraer el modelo entrenado del flujo de trabajo.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nset.seed(123)\nlibrary(brulee)\nlibrary(knitr)\n# Creamos un modelo de red neuronal.\nmodelo &lt;- mlp(hidden_units = 10) |&gt;\n    set_engine(\"brulee\") |&gt;\n    set_mode(\"classification\")\n\nmodelo_entrenado &lt;- workflow() |&gt;\n    # Añadimos la receta de preprocesamiento.\n    add_recipe(receta) |&gt;\n    # Añadimos el modelo.\n    add_model(modelo) |&gt;\n    # Entrenamos el modelo.\n    fit(data = df_entrenamiento)\n\nmodelo_entrenado |&gt;\n    # Mostramos un resumen del modelo.\n    extract_fit_engine()\n\nMultilayer perceptron\n\nrelu activation,\n10 hidden units,\n142 model parameters\n454 samples, 11 features, 2 classes \nclass weights Benigno=1, Maligno=1 \nweight decay: 0.001 \ndropout proportion: 0 \nbatch size: 409 \nlearn rate: 0.01 \nvalidation loss after 6 epochs: 0.146 \n\n\n\n\n\nEvaluar el modelo con el conjunto de test y calcular la matriz de confusión, la exactitud, y el area bajo la curva ROC.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la función augment del paquete parsnip para añadir al conjunto de test las probabilidades cada especie de pingüino.\nParámetros:\n\nnew_data: el conjunto de datos de test.\n\nUsar la función conf_mat del paquete yardstick para calcular la matriz de confusión.\nParámetros:\n\ntruth: la variable respuesta (en este caso, Especie).\nestimate: la variable con las clases predichas por el modelo (en este caso, .pred_class).\n\nUsar la función metrics del paquete yardstick para calcular las métricas de evaluación del modelo.\nParámetros:\n\ntruth: la variable respuesta (en este caso, Especie).\nestimate: la variable con las clases predichas por el modelo (en este case, .pred_class).\n\nUsar la función roc_auc del paquete yardstick para calcular el área bajo la curva ROC.\nParámetros:\n\ntruth: la variable respuesta (en este caso, Especie).\nestimate: la variable con las probabilidades de la clase positiva (en este caso, .pred_Benigno).\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Añadimos las predicciones al conjunto de test.\ndf_test &lt;- modelo_entrenado |&gt; augment(new_data = df_test)\n\n# Calculamos la matriz de confusión.\nmatriz_confusion &lt;- df_test |&gt; conf_mat(truth = Diagnostico, estimate = .pred_class) \nmatriz_confusion$table |&gt; kable()\n\n\n\n\n\nBenigno\nMaligno\n\n\n\n\nBenigno\n69\n1\n\n\nMaligno\n3\n42\n\n\n\n\n# Calculamos la exactitud.\ndf_test |&gt; metrics(truth = Diagnostico, estimate = .pred_class) |&gt;\n    # Mostramos las métricas de evaluación del modelo.\n    kable()\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\naccuracy\nbinary\n0.9652174\n\n\nkap\nbinary\n0.9264000\n\n\n\n\n# Calculamos el área bajo la curva ROC.\ndf_test |&gt; roc_auc(truth = Diagnostico, .pred_Benigno) |&gt;\n    # Mostramos el área bajo la curva ROC.\n    kable()\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nroc_auc\nbinary\n0.996447\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 7.2 El fichero vinos.csv contiene información sobre las características de vinos blancos y tintos portugueses de la denominación “Vinho Verde”. Las variables que contiene son las siguientes:\n\n\n\n\n\n\n\n\nVariable\nDescripción\nTipo (unidades)\n\n\n\n\ntipo\nTipo de vino\nFactor (blanco, tinto)\n\n\nmeses.barrica\nMeses de envejecimiento en barrica\nNumérica(meses)\n\n\nacided.fija\nCantidad de ácidotartárico\nNumérica(g/dm3)\n\n\nacided.volatil\nCantidad de ácido acético\nNumérica(g/dm3)\n\n\nacido.citrico\nCantidad de ácidocítrico\nNumérica(g/dm3)\n\n\nazucar.residual\nCantidad de azúcar remanente después de la fermentación\nNumérica(g/dm3)\n\n\ncloruro.sodico\nCantidad de clorurosódico\nNumérica(g/dm3)\n\n\ndioxido.azufre.libre\nCantidad de dióxido de azufre en forma libre\nNumérica(mg/dm3)\n\n\ndioxido.azufre.total\nCantidad de dióxido de azufre total en forma libre o ligada\nNumérica(mg/dm3)\n\n\ndensidad\nDensidad\nNumérica(g/cm3)\n\n\nph\npH\nNumérica(0-14)\n\n\nsulfatos\nCantidad de sulfato de potasio\nNumérica(g/dm3)\n\n\nalcohol\nPorcentaje de contenido de alcohol\nNumérica(0-100)\n\n\ncalidad\nCalificación otorgada por un panel de expertos\nNumérica(0-10)\n\n\n\n\nCrear un data frame con los datos del archivo vinos.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- read.csv(\"datos/vinos.csv\", stringsAsFactors = TRUE)\nglimpse(df)\n\nRows: 5,320\nColumns: 14\n$ tipo                 &lt;fct&gt; blanco, blanco, blanco, blanco, blanco, blanco, b…\n$ meses_barrica        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ acided_fija          &lt;dbl&gt; 7.0, 6.3, 8.1, 7.2, 6.2, 8.1, 8.1, 8.6, 7.9, 6.6,…\n$ acided_volatil       &lt;dbl&gt; 0.27, 0.30, 0.28, 0.23, 0.32, 0.22, 0.27, 0.23, 0…\n$ acido_citrico        &lt;dbl&gt; 0.36, 0.34, 0.40, 0.32, 0.16, 0.43, 0.41, 0.40, 0…\n$ azucar_residual      &lt;dbl&gt; 20.70, 1.60, 6.90, 8.50, 7.00, 1.50, 1.45, 4.20, …\n$ cloruro_sodico       &lt;dbl&gt; 0.045, 0.049, 0.050, 0.058, 0.045, 0.044, 0.033, …\n$ dioxido_azufre_libre &lt;dbl&gt; 45, 14, 30, 47, 30, 28, 11, 17, 16, 48, 41, 28, 3…\n$ dioxido_azufre_total &lt;dbl&gt; 170, 132, 97, 186, 136, 129, 63, 109, 75, 143, 17…\n$ densidad             &lt;dbl&gt; 1.0010, 0.9940, 0.9951, 0.9956, 0.9949, 0.9938, 0…\n$ ph                   &lt;dbl&gt; 3.00, 3.30, 3.26, 3.19, 3.18, 3.22, 2.99, 3.14, 3…\n$ sulfatos             &lt;dbl&gt; 0.45, 0.49, 0.44, 0.40, 0.47, 0.45, 0.56, 0.53, 0…\n$ alcohol              &lt;dbl&gt; 8.8, 9.5, 10.1, 9.9, 9.6, 11.0, 12.0, 9.7, 10.8, …\n$ calidad              &lt;int&gt; 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 7, 6, 8, 6, 5, 7…\n\n\n\n\n\nRealizar un análisis exploratorio de los datos.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(skimr)\nskim(df)\n\n\nData summary\n\n\nName\ndf\n\n\nNumber of rows\n5320\n\n\nNumber of columns\n14\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n13\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ntipo\n0\n1\nFALSE\n2\nbla: 3961, tin: 1359\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmeses_barrica\n0\n1\n1.23\n3.14\n0.00\n0.00\n0.00\n0.00\n24.00\n▇▁▁▁▁\n\n\nacided_fija\n0\n1\n7.22\n1.32\n3.80\n6.40\n7.00\n7.70\n15.90\n▂▇▁▁▁\n\n\nacided_volatil\n0\n1\n0.34\n0.17\n0.08\n0.23\n0.30\n0.41\n1.58\n▇▂▁▁▁\n\n\nacido_citrico\n0\n1\n0.32\n0.15\n0.00\n0.24\n0.31\n0.40\n1.66\n▇▅▁▁▁\n\n\nazucar_residual\n0\n1\n5.03\n4.41\n0.60\n1.80\n2.70\n7.50\n26.05\n▇▂▁▁▁\n\n\ncloruro_sodico\n0\n1\n0.06\n0.04\n0.01\n0.04\n0.05\n0.07\n0.61\n▇▁▁▁▁\n\n\ndioxido_azufre_libre\n0\n1\n30.04\n17.81\n1.00\n16.00\n28.00\n41.00\n289.00\n▇▁▁▁▁\n\n\ndioxido_azufre_total\n0\n1\n114.11\n56.77\n6.00\n74.00\n116.00\n153.25\n440.00\n▅▇▂▁▁\n\n\ndensidad\n0\n1\n0.99\n0.00\n0.99\n0.99\n0.99\n1.00\n1.04\n▇▂▁▁▁\n\n\nph\n0\n1\n3.22\n0.16\n2.72\n3.11\n3.21\n3.33\n4.01\n▁▇▆▁▁\n\n\nsulfatos\n0\n1\n0.53\n0.15\n0.22\n0.43\n0.51\n0.60\n2.00\n▇▃▁▁▁\n\n\nalcohol\n0\n1\n10.55\n1.19\n8.00\n9.50\n10.40\n11.40\n14.90\n▃▇▅▂▁\n\n\ncalidad\n0\n1\n5.80\n0.88\n3.00\n5.00\n6.00\n6.00\n9.00\n▁▆▇▃▁\n\n\n\n\n\n\n\n\nRecodificar la variable calidad en una variable categórica con las siguientes categorías:\n\nMuy malo: 1-2\nMalo: 3-4\nRegular: 5\nBueno: 6\nMuy bueno: 7-8\nExcelente: 9-10\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- df |&gt;\n    # Convertimos la variable calidad a un factor.\n    mutate(calidad = factor(case_when(\n        calidad %in% c(1, 2) ~ \"Muy malo\",\n        calidad %in% c(3, 4) ~ \"Malo\",\n        calidad == 5 ~ \"Regular\",\n        calidad == 6 ~ \"Bueno\",\n        calidad %in% c(7, 8) ~ \"Muy bueno\",\n        TRUE ~ \"Excelente\"\n    ), levels = c(\"Muy malo\", \"Malo\", \"Regular\", \"Bueno\", \"Muy bueno\", \"Excelente\")))\n\n\n\n\nMostrar la tabla de frecuencias de la variable calidad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    # Mostramos la tabla de frecuencias de la variable calidad.\n    count(calidad) |&gt;\n    # Mostramos la tabla de frecuencias.\n    kable()\n\n\n\n\ncalidad\nn\n\n\n\n\nMalo\n236\n\n\nRegular\n1752\n\n\nBueno\n2323\n\n\nMuy bueno\n1004\n\n\nExcelente\n5\n\n\n\n\n\n\n\n\nDividir el conjunto de datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%) estratificando por la variable calidad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidymodels)\nset.seed(123) # Semilla aleatoria para la reproducibilidad.\ndf_particion &lt;- initial_split(df, prop = 0.8, strata = \"calidad\")  # Dividir el conjunto de datos en entrenamiento (80%) y test (20%).\ndf_entrenamiento &lt;- training(df_particion) # Extraemos el conjunto de entrenamiento.\ndf_test &lt;- testing(df_particion) # Extraemos el conjunto de test.\n\n\n\n\nEstablecer la calidad como variable objetivo, normalizar las variables predictivas y convertir las variables categóricas en variables numéricas dummy.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Definimos la receta de preprocesamiento.\nreceta &lt;- recipe(calidad ~ ., data = df_entrenamiento) |&gt; \n    # Normalizamos las variables numéricas.\n    step_normalize(all_numeric_predictors()) |&gt; \n    # Convertimos las variables categóricas en variables dummy.\n    step_dummy(all_nominal_predictors()) \n\n\n\n\nConstruir una red neuronal para predecir la calidad del vino explorando distintos valores para el número de neuronas en la capa oculta (10, 15, 20, 25) mediante validación cruzada con 5 pliegues. Utilizar la precisión y el área bajo la curva ROC como métricas de evaluación.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la función tune() del paquete hardhat para definir los parámetros a optimizar. En este caso, se pueden definir los siguientes parámetros:\n\nhidden_units: el número de neuronas en la capa oculta.\n\nDespués, utilizar la función tune_grid del paquete tune para optimizar los parámetros del modelo de la red neuronal.\nParámetros:\n\nresamples: el conjunto de datos de entrenamiento particionado en pliegues para validación cruzada (en este caso, vfold_cv(df_entrenamiento, v = 5)).\ngrid: un data frame con los valores de los parámetros a probar.\n\nUsar la función autoplot() del paquete tune para visualizar los resultados de la optimización.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nset.seed(123) # Semilla aleatoria para la reproducibilidad.\nlibrary(brulee)\n# Creamos un modelo de red neuronal con un número variable de neuronas en la capa oculta.\nmodelo &lt;- mlp(hidden_units = tune()) |&gt;\n    set_engine(\"brulee\") |&gt;\n    set_mode(\"classification\")\n\nflujo &lt;- workflow() |&gt;\n    # Añadimos la receta de preprocesamiento.\n    add_recipe(receta) |&gt;\n    # Añadimos el modelo.\n    add_model(modelo)\n\nmodelos_entrenados &lt;- flujo |&gt;\n# Entrenamos los modelos con diferentes valores de neuronas en la capa oculta.\n    tune_grid(\n        resamples = vfold_cv(df_entrenamiento, v = 5), # Validación cruzada con 5 pliegues.\n        control = control_grid(save_pred = TRUE), # Guardamos las predicciones.\n        grid = tibble(hidden_units = seq(10, 25, by = 5)), # Valores de neuronas a probar.\n        metrics = metric_set(accuracy, roc_auc) # Métricas de evaluación.\n    ) \n\n# Visualizamos los resultados de la validación cruzada.\n    autoplot(modelos_entrenados) \n\n\n\n\n\n\n\n\n\n\n\nSeleccionar el mejor modelo según la exactitud y entrenarlo con el conjunto de entrenamiento.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmodelo_final &lt;- flujo |&gt;\n    # Seleccionamos el mejor modelo según la exactitud.\n    finalize_workflow(select_best(modelos_entrenados, metric = \"accuracy\")) |&gt; \n    # Entrenamos el modelo con el conjunto de entrenamiento.\n    last_fit(df_particion, metrics = metric_set(accuracy, roc_auc))\n# Mostramos un resumen del modelo.\nmodelo_final |&gt;\n    extract_fit_engine() \n\nMultilayer perceptron\n\nrelu activation,\n25 hidden units,\n506 model parameters\n4,255 samples, 13 features, 6 classes \nclass weights Muy malo=1, Malo=1, Regular=1, Bueno=1, Muy bueno=1, Excelente=1 \nweight decay: 0.001 \ndropout proportion: 0 \nbatch size: 3830 \nlearn rate: 0.01 \nvalidation loss after 13 epochs: 0.874 \n\n\n\n\n\nEvaluar el modelo con el conjunto de test y la exactitud y el área bajo la curva ROC.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Extraemos las métricas de evaluación del modelo entrenado.\n    collect_metrics(modelo_final) |&gt; kable()\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nmulticlass\n0.6018779\nPreprocessor1_Model1\n\n\nroc_auc\nhand_till\n0.8050608\nPreprocessor1_Model1",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "07-redes-neuronales.html#ejercicios-propuestos",
    "href": "07-redes-neuronales.html#ejercicios-propuestos",
    "title": "7  Redes Neuronales",
    "section": "7.2 Ejercicios Propuestos",
    "text": "7.2 Ejercicios Propuestos\n\nEjercicio 7.3 El fichero infartos.csv contiene información sobre distintas variables fisiológicas relacionadas con el riesgo de infarto de una muestra de personas. Las variables que contienen son:\n\nEdad: Edad del paciente (años)\nSexo: Sexo del paciente (H: hombre, M: mujer)\nDolorPecho: Tipo de dolor torácico (TA: angina típica, ATA: angina atípica, NAP: dolor no anginoso, ASY: asintomático)\nPresionArterial: Presión arterial sistólica en reposo (mm Hg)\nColesterol: Colesterol sérico (mm/dl)\nGlucemia: Glucemia en ayunas (1: si glucemia en ayunas &gt; 120 mg/dl, 0: de lo contrario)\nElectro: resultados del electrocardiograma en reposo (Normal: normal, ST: anomalía onda ST-T (inversiones de onda T y/o elevación o depresión de ST &gt; 0,05 mV), LVH: hipertrofia ventricular izquierda probable o definitiva según criterios de Estes)\nPulsaciones: Frecuencia cardíaca máxima alcanzada (valor numérico entre 60 y 202)\nAnginaEjercicio: Angina inducida por ejercicio (S: sí, N: no)\nDepresionST: Depresión del segmento ST inducida por el ejercicio (valor numérico de la depresión).\nPendienteST: Pendiente del segmento ST en el pico de ejercicio (Ascendente, Plano, Descencdente).\nInfarto: Riesgo de infarto (1: Sí, 0: No)\n\n\nCrear un dataframe con los datos del archivo infartos.csv.\nRealizar un análisis exploratorio de los datos.\nDividir el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test. Utilizar el 80% de los datos para entrenamiento y el 20% restante para test.\nConstruir una red neuronal para predecir el riesgo de infarto explorando distinto número de neuronas en la capa oculta y validando los modelos mediante validación cruzada de 5 pliegues. ¿Qué número de neuronas tiene el mejor modelo según la exactitud?\nEntrenar el mejor modelo del apartado anterior con el conjunto de entrenamiento y evaluarlo con el conjunto de test. Calcular la matriz de confusión y también la precisión, sensibilidad y la especificidad.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  }
]